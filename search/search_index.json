{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p><code>cymyc</code> is a library for numerical differential geometry on Calabi-Yau manifolds written in JAX, enabling performant:</p> <ul> <li>Approximations of useful tensor fields;</li> <li>Computations of curvature-related quantities;</li> <li>Investigations of the complex structure moduli space;</li> </ul> <p>in addition to many other features. </p> <p>If you are new to Jax and want to get your hands dirty, then start with this example.</p>"},{"location":"#installation","title":"Installation","text":"<p>First, clone the project:</p> <pre><code>git clone git@github.com:Justin-Tan/cymyc.git\ncd cymyc\n</code></pre> <p>Next, with a working Python installation, create a new virtual environment and run an editable install, which permits local development.</p> <p><pre><code>pip install --upgrade pip\npython -m venv /path/to/venv\nsource /path/to/venv/bin/activate\n\npython -m pip install -e .\n</code></pre> Requires Python &gt;=3.10 - all needed dependencies will be automatically installed. See this example on how to use the main scripts.</p> <p>Tip</p> <p>This library is device-agnostic. That being said, autodiff routines will usually be significantly faster if the user has access to a GPU. If this applies to you, follow the Jax GPU installation instructions to enable GPU support.</p>"},{"location":"#contributing-development","title":"Contributing / Development","text":"<p>This library is under active development, and the current state is but the leading order approximation. Please open an issue / pull request if you encounter unexpected behaviour. Additionally, feel free to get in touch anytime to discuss the project or help us guide development.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you found this library to be useful in academic work, then please cite: (arxiv). <pre><code>@article{cymyc,\n    author = {Butbaia, Giorgi, Tan, Justin, ...},\n    title = {\\textsf{cymyc}: {\\it A \\textsf{{JAX}} package for {C}alabi--{Y}au \n    {M}etrics {Y}ukawas and {C}urvature}},\n    eprint = \"2410.19728\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"hep-th\",\n    month = \"10\",\n    year = \"2024\"\n}\n</code></pre></p> <p>The source code is available on GitHub.</p>"},{"location":"#related-work","title":"Related work","text":"<p>This codebase was used to generate the 'experimental' results for the following publications:</p> <ol> <li>Curvature on Calabi-Yau manifolds - arxiv:2211.90801.</li> <li>Physical Yukawa couplings in heterotic string compactifications - arxiv:2401.15078.</li> <li>Precision string phenomenology - arxiv:2407.13836.</li> </ol>"},{"location":"#related-libraries-acknowledgements","title":"Related libraries / Acknowledgements","text":"<p>We would like to acknowledge the authors of the cymetric library (Larfors et. al. (2022)), whose excellent work this library builds upon.</p> <p>Numerical metrics on Calabi-Yaus</p> <ul> <li>cymetric - Python library for studying Calabi-Yau metrics.</li> <li>cyjax - Donaldson's algorithm for Calabi-Yau metrics in Jax.</li> <li>MLGeometry - Machine learning Calabi-Yau metrics</li> </ul> <p>JAX ecosystem</p> <ul> <li>equinox - JAX enhancement suite.</li> <li>flax - Neural network library.</li> </ul>"},{"location":"faq/","title":"FAQ","text":"<p>Questions you may or may not have had about this library. </p>"},{"location":"faq/#why-write-in-it-jax","title":"Why write in it <code>Jax</code>?","text":"<p><code>Jax</code> is a high-performance Python library for program transformations - chief among these being automatic differentiation. This is the transformation of a program into another another, $$ \\texttt{program} \\rightarrow \\partial(\\texttt{program})~, $$  which evaluates the partial derivative with respect to any of \\(\\texttt{program}\\)'s original inputs. From a computational geometry perspective, this is a boon for computation of curvature-related quantities and differential operators on manifolds. For example, given a program which outputs the metric tensor \\(g_{\\mu \\nu}\\) in local coordinates, one schematically arrives at the various horsemen of curvature via derivatives w.r.t. local coordinates,</p> \\[  \\left(g_{\\mu \\nu} \\sim \\partial \\partial \\varphi \\right) \\stackrel{\\partial}{\\rightarrow} \\left(\\Gamma^{\\kappa}_{\\mu \\nu} \\sim g \\cdot \\partial g\\right) \\stackrel{\\partial}{\\rightarrow} \\left(R^{\\kappa}_{\\, \\, \\lambda \\mu \\nu} \\sim \\partial \\Gamma + \\Gamma \\cdot \\Gamma\\right) \\rightarrow \\cdots ~. \\] <p>What distinguishes <code>Jax</code> from other autodiff / machine learning frameworks is that idiomatic <code>Jax</code> uses a functional programming paradigm. The price one pays for the significant performance boost afforded by <code>Jax</code> for most scientific computing applications are additional constraints on program logic, which would not be present in Python or other libraries which use an imperative paradigm. </p> <p>Somewhat loosely, when using <code>Jax</code>, one is usually not writing code to be executed by the Python interpreter, rather building a graph of computations which will be compiled and passed to an accelerator, which is typically orders of magnitude faster than regular Python code (and \\(\\mathcal{O}(1)\\) faster than Torch/Tensorflow, in our experience). The flip side is that the compilation procedure restricts the program logic to a subset of possible operations relative to other autodiff frameworks.</p> <p>A full discussion of the <code>Jax</code> model is beyond the scope here, and we defer to the excellent official guides on this matter. However, as a quick summary:</p> <ol> <li>The <code>Jax</code> computational model is to express algorithms in terms of operations on immutable data structures using pure functions.</li> <li>Written in this way, useful program transformations (differentiation, compilation, vectorisation, etc.) may be automatically applied by the framework without further intervention.</li> </ol> <p>Most of these complications are not exposed to end users, but being aware of this is important if attempting to build on top of this library.</p>"},{"location":"faq/#adding-custom-architectures","title":"Adding custom architectures","text":"<p>There are multiple routes to add new architectures for approximation of various tensor fields. The simplest one is just to provide a Jax function, but the recommended route, keeping in line with the logic in the models module, is to add:</p> <ol> <li>A Flax module describing the sequence of operations defined by your architecture. <pre><code>import jax.numpy as jnp\nfrom flax import linen as nn\n\nclass MyAnsatz(nn.Module):\n    # toy example\n    def setup(self):\n        self.layer = nn.Einsum(...)   # some logic\n\n    @nn.compact\n    def __call__(self, local_coords):\n        p = local_coords\n        p_bar = jnp.conjugate(p)\n        p_norm_sq = jnp.sum(p * p_bar)\n        return jnp.outer(p, p_bar) / p_norm_sq + self.layer(p)\n</code></pre></li> <li>A pure function which accepts a pytree of parameters for the model and executes the computation by invoking the <code>.apply</code> method of the module you defined above. <pre><code>def tensor_ansatz(p, params, *args):\n    p = ...  # some logic\n    model = MyAnsatz(*args)  # model constructor\n    return model.apply({'params': params}, p)\n</code></pre></li> </ol>"},{"location":"faq/#downstream-computations","title":"Downstream computations","text":"<p>You have run some optimisation procedure, obtaining a parameterised function which approximates some tensor field in local coordinates. For concreteness, let us say this is the metric tensor. As it is likely that any downstream computation will involve some differential operator, it is recommended to apply a partial closure, binding all arguments except for the coordinate dependency. </p> <p>It is recommended to use <code>Jax</code>'s pytree-compatible partial evaluation instead of the conventional <code>functools.partial</code> call, such that the function may be passed as an argument to transformed <code>Jax</code> functions. <pre><code>import jax\nimport jax.numpy as jnp\n\ndef approx_metric_fn(p, params, *args):\n    g = ... # some logic\n    return g\n\n@jax.jit\ndef christoffel_symbols(p, metric_fn):\n    g_inv = jnp.linalg.inv(metric_fn(p))\n    jac_g_holo = del_z(p, metric_fn)\n    return jnp.einsum('...kl, ...jki-&gt;...lij', g_inv, jac_g_holo)\n\nmetric_fn = jax.tree_util.Partial(approx_metric_fn, params, *args)\nGamma = christoffel_symbols(p, metric_fn)\n</code></pre></p>"},{"location":"faq/#functions-accessing-global-state","title":"Functions accessing global state","text":"<p>Because useful program transformations assume that the functions they act on are pure, functions which read or write to global state can result in undefined behaviour. The simplest way to resolve this is to manually carry around arguments to functions. This is clunky in general and may be alleviated through a partial closure for static arguments, using <code>functools.partial</code> or <code>tree_util.partial</code> for compatibility with program transformations. Another alternative is to use filtered transformations, as in Equinox. </p>"},{"location":"faq/#the-compiler-throws-an-arcane-error","title":"The compiler throws an arcane error","text":"<p>Most of the time, this is due to:</p> <ul> <li>Program logic violating the constraints placed by the XLA compiler, and the resolution can be found in this compendium.</li> <li>Memory issues when computing curvature quantities which involve higher-order derivatives of some neural network architecture with respect to the input points. In this case try reducing the <code>vmap</code> batch size or decrease the complexity of the architecture.</li> </ul> <p>However, there can be a few truly head-scratching errors. In that case, please raise an issue or feel free to contact us.</p>"},{"location":"faq/#miscellanea","title":"Miscellanea","text":"<p>Dev notes that don't fit anywhere else.</p> <ul> <li>The documentation uses the jaxtyping conventions for array annotations.</li> <li>A good chunk of code is not exposed to the public API as it is mostly for internal purposes or privileged downstream packages. Please get in touch if the comments are insufficient and you want the docs to be expanded.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>This library is a tool for numerical differential geometry, with a focus on K\u00e4hler geometry and calculations related to string compactifications. </p>"},{"location":"overview/#the-jax-computational-paradigm","title":"The <code>Jax</code> computational paradigm","text":"<p><code>Jax</code> is a high-performance Python library for program transformations - chief among these being automatic differentiation. This is the transformation of a program into another,  $$ \\texttt{program} \\rightarrow \\partial(\\texttt{program})~, $$  which evaluates the partial derivative with respect to any of \\(\\texttt{program}\\)'s original inputs. From a computational geometry perspective, this is a boon for computation of curvature-related quantities and differential operators on manifolds. For example, given a program which outputs the metric in local coordinates, one schematically arrives at the various horsemen of curvature via derivatives w.r.t. local coordinates,</p> \\[      \\varphi \\stackrel{\\partial}{\\rightarrow} \\left(g_{\\mu \\nu} \\sim \\partial \\partial \\varphi \\right) \\stackrel{\\partial}{\\rightarrow} \\left(\\Gamma^{\\kappa}_{\\mu \\nu} \\sim g \\cdot \\partial g\\right) \\stackrel{\\partial}{\\rightarrow} \\left(R^{\\kappa}_{\\, \\, \\lambda \\mu \\nu} \\sim \\partial \\Gamma + \\Gamma \\cdot \\Gamma\\right) \\rightarrow \\cdots  \\]"},{"location":"overview/#philosophy","title":"Philosophy","text":"<p>The pullback metric \\(\\iota^* g\\) may be computed as:</p> \\[     \\iota^* g = J^T g J\\,. \\]"},{"location":"overview/#abstract-nonsense","title":"abstract nonsense","text":"curvature<pre><code>import jax\nimport jax.numpy as jnp\n\nimport numpy as np\n\ndef metric_fn(p):\n    return \n\ndef christoffel_symbols(p):\n    return del_z(p, metric_fn)\n</code></pre> <p>Tip</p> <p>This library is device-agnostic. That being said, autodiff routines will usually be significantly faster if the user has access to a GPU. If this applies to you, follow the Jax GPU installation instructions to enable GPU support.</p> <p>Note</p> <p>This is a note.</p> <p>Tip</p> <p>This is a tip.</p> <p>Info</p> <p>and this is an info block.</p>"},{"location":"api/chern_gauss_bonnet/","title":"Chern gauss bonnet","text":""},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet","title":"<code>cymyc.chern_gauss_bonnet</code>","text":"<p>Calculation of topological invariants (Chern classes, Euler characteristic) for a general Kahler manifold. Note some functions may specialise to the case of a projective variety. Note the following:</p> <ul> <li>As with curvature, these functions involve \\(n\\)-th order derivatives of some function <code>fun</code>. These are  computed with autodiff - a good usage pattern is to make a partial closure to bind all arguments to <code>fun</code> except the coordinate dependence.</li> <li>These functions expect local coordinates <code>z</code> in a <code>c_dim</code>-dimensional space, with the  real and imaginary parts concatenated to form a real-valued <code>2*c_dim</code> vector, <code>p = [Re(z); Im(z)]</code>.</li> <li>The Euler characteristic is defined up to an integer factor from the normalisation of the volume form. The canonical choice is to normalise according to the intersection number computation.</li> </ul>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.riem_real","title":"<code>riem_real(p: Float[Array, 2 * i], metric_fn: Callable[[Array], Array], *args: Sequence, pullbacks: Optional[Float[Array, 'dim i']] = None, return_down: bool = False) -&gt; Float[Array, '2*dim 2*dim 2*dim 2*dim']</code>","text":"<p>Viewing the \\(n\\)-dim K\u00e4hler manifold as a real \\((2n)\\)-dimensional manifold, computes the real  \\((2n)\\)-dimensional Riemann tensor corresponding to the given metric tensor.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords with <code>float</code> type at which <code>fun</code> is evaluated.  Consists of the concatenation of real and imaginary parts along the last axis.</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates.</p> required <code>*args</code> <code>tuple</code> <p>Additional arguments to pass to <code>metric_fn</code>.</p> <code>()</code> <code>pullbacks</code> <code>array_like</code> <p>Pullback matrix from ambient to projective variety. If supplied, computes Riemann tensor on the variety, by default None.</p> <code>None</code> <code>return_down</code> <code>bool</code> <p>If True, return the Riemann tensor with all indices lowered, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>array_like</code> <p>The real (2n)-dimensional Riemann tensor. If <code>return_down</code> is True, returns the tensor with all indices lowered.</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.chern1","title":"<code>chern1(riem: Complex[Array, 'dim dim dim dim']) -&gt; Complex[Array, 'dim dim']</code>","text":"<p>Computes the first Chern class. Let \\(\\mathcal{R} \\in \\Omega^2_X\\left(\\text{End}(T_X)\\right)\\) be the curvature two-form on \\(X\\), then $$ c_1 \\propto \\textsf{Tr}\\mathcal{R}~.$$</p> <p>Parameters:</p> Name Type Description Default <code>riem</code> <code>array_like</code> <p>(1,3) Riemann tensor corresponding to the Kahler connection  \\(R^{\\kappa}_{\\lambda \\mu \\bar{\\nu}}\\).</p> required <p>Returns:</p> Type Description <code>array_like</code> <p>First Chern form.</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.chern2","title":"<code>chern2(riem: Complex[Array, 'dim dim dim dim']) -&gt; Complex[Array, 'dim dim dim dim']</code>","text":"<p>Computes the second Chern class, $$ c_2 \\propto \\left(\\textsf{Tr}\\mathcal{R}^2 - \\textsf{Tr}\\mathcal{R} \\wedge \\textsf{Tr}\\mathcal{R} \\right)~.$$</p> <p>Parameters:</p> Name Type Description Default <code>riem</code> <code>array_like</code> <p>(1,3) Riemann tensor corresponding to the Kahler connection  \\(R^{\\kappa}_{\\lambda \\mu \\bar{\\nu}}\\).</p> required <p>Returns:</p> Name Type Description <code>c2</code> <code>array_like</code> <p>Second Chern form.</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.chern3","title":"<code>chern3(riem: Complex[Array, 'dim dim dim dim']) -&gt; Complex[Array, '']</code>","text":"<p>Computes the third Chern class,</p> \\[ c_3 \\propto c_1 \\wedge c_2 + c_1 \\wedge \\textsf{Tr} \\mathcal{R}^2 - \\textsf{Tr}\\mathcal{R}^3~. \\] <p>Parameters:</p> Name Type Description Default <code>riem</code> <code>array_like</code> <p>(1,3) Riemann tensor corresponding to the Kahler connection  \\(R^{\\kappa}_{\\lambda \\mu \\bar{\\nu}}\\).</p> required <p>Returns:</p> Name Type Description <code>c3</code> <code>array_like</code> <p>The third Chern form, expressed as the coefficient of the complex wedgey part  in standard form: \\(dz^1 \\wedge d\\bar{z}^1 \\wedge \\cdots \\wedge dz^n \\wedge d\\bar{z}^n\\).</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.chern4","title":"<code>chern4(riem: Complex[Array, 'dim dim dim dim']) -&gt; Complex[Array, '']</code>","text":"<p>Computes the fourth Chern class,</p> \\[ c_4 \\propto c_1^4 + c_1^2 \\wedge \\textsf{Tr}{\\mathcal{R}}^2 + c_1 \\wedge \\textsf{Tr} \\mathcal{R}^3 \\       +  (\\textsf{Tr}\\mathcal{R}^2)^2 - \\textsf{Tr}\\mathcal{R}^4~. \\] <p>Parameters:</p> Name Type Description Default <code>riem</code> <code>array_like</code> <p>(1,3) Riemann tensor corresponding to the Kahler connection  \\(R^{\\kappa}_{\\lambda \\mu \\bar{\\nu}}\\).</p> required <p>Returns:</p> Name Type Description <code>c4</code> <code>array_like</code> <p>The fourth Chern form, expressed as the coefficient of the complex wedgey part  in standard form: \\(dz^1 \\wedge d\\bar{z}^1 \\wedge \\cdots \\wedge dz^n \\wedge d\\bar{z}^n\\).</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.euler_characteristic","title":"<code>euler_characteristic(data: Tuple[Float[Array, 2 * i], Float[Array, ''], Float[Array, '']], pullbacks: Optional[Float[Array, 'dim i']], metric_fn: Callable[[Array], Array], cy_dim: int = 3) -&gt; Float[Array, '']</code>","text":"<p>Computes the Euler characteristic from the Pfaffian of the curvature two-form \\(\\mathcal{R} \\in \\Omega^2_X(T_X)\\), with support for Calabi-Yau \\(n\\)-folds for \\(n=1,2,3\\).</p> \\[\\chi = \\frac{1}{(2\\pi)^n} \\int_X \\textsf{Pf}(\\mathcal{R})~.\\] <p>Parameters:</p> Name Type Description Default <code>data</code> <code>tuple</code> <p>A tuple containing coordinates <code>p</code>, weights, and the volume form <code>dVol_Omega</code>.</p> required <code>pullbacks</code> <code>array_like</code> <p>Pullback matrix from ambient to projective variety. If supplied, computes the Euler characteristic  on the variety, by default None.</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates.</p> required <code>cy_dim</code> <code>int</code> <p>Complex dimension of Calabi-Yau, default 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>chi</code> <code>array - like</code> <p>The Euler characteristic.</p>"},{"location":"api/chern_gauss_bonnet/#cymyc.chern_gauss_bonnet.euler_characteristic_form","title":"<code>euler_characteristic_form(data: Tuple[Float[Array, 2 * i], Float[Array, ''], Float[Array, '']], pullbacks: Optional[Float[Array, 'dim i']], metric_fn: Callable[[Array], Array], cy_dim: int = 3) -&gt; Float[Array, '']</code>","text":"<p>Computes the Euler characteristic via integration of the top Chern class over \\(X\\) for a Calabi-Yau n-fold.</p> \\[\\chi = \\int_X c_n~.\\] <p>Parameters:</p> Name Type Description Default <code>data</code> <code>tuple</code> <p>A tuple containing coordinates <code>p</code>, weights, and the volume form <code>dVol_Omega</code>.</p> required <code>pullbacks</code> <code>array_like</code> <p>Pullback matrix from ambient to projective variety. If supplied, computes the Euler characteristic  on the variety, by default None.</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates.</p> required <code>cy_dim</code> <code>int</code> <p>Complex dimension of Calabi-Yau.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>chi</code> <code>array - like</code> <p>Contribution to Euler characteristic for each point in <code>data</code>.</p>"},{"location":"api/curvature/","title":"Curvature","text":""},{"location":"api/curvature/#cymyc.curvature","title":"<code>cymyc.curvature</code>","text":"<p>Calculation of various curvature-related quantities for a general Kahler manifold \\(X\\). This module may also be used to compute curvature information on a real manifold without complex structure, by omitting the imaginary part of the local coordinates for \\(p \\in X\\).</p> <p>Note the following:</p> <ul> <li>Curvature quantities involve \\(n\\)-th order derivatives of some generic function <code>fun</code>. These are  computed with autodiff - a good usage pattern is to make a partial closure to bind all arguments to <code>fun</code> except the coordinate dependence.</li> <li>These functions expect local coordinates <code>z</code> in a <code>c_dim</code>-dimensional space, with the  real and imaginary parts concatenated to form a real-valued <code>2*c_dim</code> vector, <code>p = [Re(z); Im(z)]</code>.</li> </ul> <p>Info</p> <p>When transforming functions which compute derivatives of some <code>fun</code> passed as an input, you will need to either:</p> <ul> <li>In the case of <code>jit</code>, specify that <code>fun</code> is a static argument.</li> <li>Wrap <code>fun</code> in a <code>jax.tree_util.Partial</code> closure to make it compatible with Jax transformations.</li> </ul> <p>See the below example.</p> <p>Example</p> <pre><code>import jax\nimport jax.numpy as jnp\nfun = lambda x: jnp.sum(jnp.cos(x))\n\n&gt;&gt;&gt; jax.jit(del_z, static_argnums=(1,))(p, fun)  # ok\n&gt;&gt;&gt; jax.jit(del_z)(p, jax.tree_util.Partial(fun))  # ok\n&gt;&gt;&gt; jax.jit(del_z)(p, fun)  # TypeError\n</code></pre>"},{"location":"api/curvature/#cymyc.curvature.del_z","title":"<code>del_z(p: Float[Array, i], fun: Callable[[Float[Array, ...]], Array], wide: bool = False, *args) -&gt; Complex[Array, '... i']</code>","text":"<p>Holomorphic derivative of a function.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords with <code>float</code> type at which <code>fun</code> is evaluated.  Consists of the concatenation of real and imaginary parts along the last axis.</p> required <code>fun</code> <code>callable</code> <p>Locally defined function fun: \\(\\mathbb{R}^m -&gt; \\mathbb{C}^{a,b,c...}\\) sending real-valued  inputs to complex-valued outputs</p> required <p>Returns:</p> Name Type Description <code>dfun_dz</code> <code>array_like</code> <p>Holomorphic derivative of <code>fun</code>.</p> Notes <p>Computes holomorphic Wirtinger derivative, w.r.t. complex \\(p = x + iy\\).</p> \\[ \\frac{\\partial f}{\\partial z} = \\frac{1}{2}\\left( \\frac{\\partial f}{\\partial x} - i \\frac{\\partial f}{\\partial y} \\right) \\] <p>Examples:</p> <pre><code>&gt;&gt;&gt; p = jnp.ones((8,))\n&gt;&gt;&gt; fun = lambda x: jnp.sum(jnp.cos(x))\n&gt;&gt;&gt; del_z(p, fun)\nArray([-0.42073548+0.42073548j, -0.42073548+0.42073548j,\n       -0.42073548+0.42073548j, -0.42073548+0.42073548j], dtype=complex64)\n</code></pre>"},{"location":"api/curvature/#cymyc.curvature.del_bar_z","title":"<code>del_bar_z(p: Float[Array, i], fun: Callable[[Float[Array, ...]], Array], wide: bool = False, *args) -&gt; Complex[Array, '... i']</code>","text":"<p>Anti-holomorphic derivative of a function.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at  which <code>fun</code> is evaluated. Shape [i].</p> required <code>fun</code> <code>callable</code> <p>Locally defined function fun: \\(\\mathbb{R}^m -&gt; \\mathbb{C}^{a,b,c...}\\) sending real-valued  inputs to complex-valued outputs</p> required <p>Returns:</p> Name Type Description <code>dfun_dz_bar</code> <code>array_like</code> <p>Anti-holomorphic derivative of <code>fun</code>.</p>"},{"location":"api/curvature/#cymyc.curvature.del_z_bar_del_z","title":"<code>del_z_bar_del_z(p: Float[Array, i], fun: Callable[[Float[Array, ...]], Array], *args, wide: bool = False) -&gt; Complex[Array, '... i i']</code>","text":"<p>Computes the composition \\(\\partial \\circ \\overline{\\partial}\\) of a given function. Note this  coincides with the Hessian \\(\\nabla df\\) on a complex manifold.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>fun</code> <code>callable</code> <p>Locally defined function fun: \\(\\mathbb{R}^m -&gt; \\mathbb{C}^{a,b,c...}\\) sending real-valued  inputs to complex-valued outputs</p> required <code>wide</code> <code>bool</code> <p>Flag to use reverse-mode autodiff if function is wide, i.e. if the output of  <code>fun</code> is a scalar.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dfun_dz_bar_dz</code> <code>array_like</code> <p>\\(\\bar{\\partial} \\partial f\\). Shape [..., \\mu, \\bar{\\nu}]. Note holomorphic index  comes first.</p>"},{"location":"api/curvature/#cymyc.curvature.christoffel_symbols_kahler","title":"<code>christoffel_symbols_kahler(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None) -&gt; Complex[Array, 'j j j']</code>","text":"<p>Returns holomorphic Levi-Civita connection coefficients, with optional  support for variety \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\). Schematically, if \\(g\\) is the metric tensor, $$ \\Gamma \\sim g^{-1} \\cdot \\partial g~. $$</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <p>Returns:</p> Name Type Description <code>gamma_holo</code> <code>array_like</code> <p>Holomorphic Christoffel symbols of the Kahler metric. \\(\\Gamma^{\\lambda}_{\\mu \\nu}\\). Shape [...,k,i,j], symmetric in (i,j). The Kahler conditions  imply \\(\\Gamma^{\\lambda}_{\\mu \\nu}\\) and its conjugate are the only nonzero connection coeffs.</p> <p>Other Parameters:</p> Name Type Description <code>pullbacks</code> <code>array_like</code> <p>Pulllback matrices from ambient to projective variety. If supplied, computes Christoffels on the variety.</p>"},{"location":"api/curvature/#cymyc.curvature.riemann_tensor_kahler","title":"<code>riemann_tensor_kahler(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None, return_aux: bool = False) -&gt; Complex[Array, 'j j j j'] | Sequence[Array]</code>","text":"<p>Returns Riemann curvature tensor on a K\u00e4hler manifold, with optional support for variety \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\). This can also be used to construct the Riemann tensor on a real manifold by omission of the imaginary part of <code>p</code>. Schematically, $$ \\textsf{Riem} \\sim \\partial \\Gamma + \\Gamma \\Gamma ~. $$</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> <p>Warning</p> <p>This function explicitly instantiates the complex Hessian of <code>metric_fn</code> - this may result in  memory issues if <code>vmap</code>-ing over a large batch. Try reducing the batch size or reducing the complexity of <code>metric_fn</code> if memory-constrained.</p> required <p>Returns:</p> Name Type Description <code>riemann</code> <code>array_like</code> <p>(1,3) Riemann tensor corresponding to the Kahler connection \\(R^{\\kappa}_{\\lambda \\mu \\overline{\\nu}}\\). See page 335, (8.97) of Nakahara.</p> <p>Other Parameters:</p> Name Type Description <code>pullbacks</code> <code>array_like</code> <p>Pulllback matrices from ambient to projective variety. If supplied, computes Riemann tensor on the variety.</p>"},{"location":"api/curvature/#cymyc.curvature.ricci_tensor_kahler","title":"<code>ricci_tensor_kahler(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None) -&gt; Complex[Array, 'j j']</code>","text":"<p>Returns Ricci curvature tensor on a K\u00e4hler manifold, with optional support for variety  \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <p>Returns:</p> Name Type Description <code>ricci</code> <code>array_like</code> <p>(0,2) Ricci tensor corresponding to the Kahler connection $ R_{\\mu \\bar{\\nu}}$.</p> <p>Other Parameters:</p> Name Type Description <code>pullbacks</code> <code>array_like</code> <p>Pulllback matrices from ambient to projective variety. If supplied, computes Ricci tensor on the variety.</p> See Also <p><code>ricci_form_kahler</code> : Computes Ricci form as \\(\\partial_{\\mu} \\overline{\\partial}_{\\overline{\\nu}} \\log g\\).</p>"},{"location":"api/curvature/#cymyc.curvature.ricci_form_kahler","title":"<code>ricci_form_kahler(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None) -&gt; Complex[Array, 'j j']</code>","text":"<p>Returns Ricci form \\(\\rho\\) on a K\u00e4hler manifold, with support for variety \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\).  Componentwise, \\(\\rho_{\\mu\\bar{\\nu}} = i R_{\\mu \\bar{\\nu}}\\), and $$ \\rho = \\partial \\overline{\\partial} \\log \\det g~. $$</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <p>Returns:</p> Name Type Description <code>ricci</code> <code>array_like</code> <p>(1,1) Ricci form corresponding to the Kahler connection $ R_{\\mu \\bar{\\nu}}$.</p> <p>Other Parameters:</p> Name Type Description <code>pullbacks</code> <code>array_like</code> <p>Pulllback matrices from ambient to projective variety. If supplied, computes Ricci tensor on the variety.</p>"},{"location":"api/curvature/#cymyc.curvature.ricci_scalar","title":"<code>ricci_scalar(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None) -&gt; Complex[Array, '']</code>","text":"<p>Returns Ricci scalar on a K\u00e4hler manifold, with support for variety \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\). </p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <p>Returns:</p> Name Type Description <code>R</code> <code>array_like</code> <p>Ricci scalar, \\(R = g^{\\mu \\bar{\\nu}}R_{\\mu \\bar{\\nu}}\\). Shape [...]</p> <p>Other Parameters:</p> Name Type Description <code>pullbacks</code> <code>array_like</code> <p>Pulllback matrices from ambient to projective variety. If supplied, computes Ricci tensor on the variety.</p>"},{"location":"api/fubini_study/","title":"Fubini study","text":""},{"location":"api/fubini_study/#cymyc.fubini_study","title":"<code>cymyc.fubini_study</code>","text":"<p>Computation of the Fubini-Study metric - the unique \\(U(n+1)\\) Riemannian metric on \\(\\mathbb{P}^n\\) + associated functions.</p>"},{"location":"api/fubini_study/#cymyc.fubini_study.fubini_study_metric","title":"<code>fubini_study_metric(p: Float[Array, i], normalization: Complex = jax.lax.complex(1.0, 0.0), cdtype: DTypeLike = np.complex64)</code>","text":"<p>Returns Fubini-Study metric in \\(\\mathbb{P}^n\\) evaluated at <code>p</code> in inhomogeneous coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>2*n real inhomogeneous coords at which metric is evaluated. Shape [i].</p> required <p>Returns:</p> Name Type Description <code>g_FS</code> <code>array_like</code> <p>Hermitian metric in local coordinates, \\(g_{\\mu \\bar{\\nu}}\\). Shape [i,j].</p>"},{"location":"api/fubini_study/#cymyc.fubini_study.fubini_study_metric_homo","title":"<code>fubini_study_metric_homo(p: Float[Array, i], normalization: Complex = jax.lax.complex(1.0, 0.0), cdtype: DTypeLike = np.complex64)</code>","text":"<p>Returns Fubini-Study metric in \\(\\mathbb{P}^n\\) evaluated at <code>p</code> in homogeneous coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>2*(n+1) real homogeneous coords at which metric is evaluated. Shape [i].</p> required <p>Returns:</p> Name Type Description <code>g_FS</code> <code>array_like</code> <p>Hermitian metric in local coordinates, \\(g_{\\mu \\bar{\\nu}}\\). Shape [i,j].</p> <p>Warning</p> <p>Note the returned metric is expressed in homogeneous coordinates and will not be of full rank.</p>"},{"location":"api/fubini_study/#cymyc.fubini_study.fubini_study_metric_homo_pb","title":"<code>fubini_study_metric_homo_pb(p: Float[Array, i], dQdz_info: tuple, cy_dim: int, normalization: Complex = jax.lax.complex(1.0, 0.0), ambient_out: bool = False, cdtype: DTypeLike = np.complex64)</code>","text":"<p>Returns FS metric on hypersurfaces \\(X\\) immersed in \\(\\mathbb{P}^n\\) evaluated  at <code>p</code> in homogeneous coordinates, i.e. \\([x_1 : x_2: \\cdots : x_{n+1}]\\). This is the  ambient FS metric in CP^n pulled back by the inclusion map: \\(\\iota: X \\hookrightarrow \\mathbb{P}^n\\). </p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2*(n+1) real homogeneous coords at which metric is evaluated. Shape [i].</p> required <p>Returns:</p> Name Type Description <code>g_FS_pb</code> <code>array_like</code> <p>Hermitian metric pulled back to \\(X\\) in local coordinates, \\(g_{\\mu \\bar{\\nu}}\\). Shape [i,j].</p>"},{"location":"api/fubini_study/#cymyc.fubini_study.fubini_study_metric_homo_pb_cicy","title":"<code>fubini_study_metric_homo_pb_cicy(p: Float[Array, i], pullbacks: Complex[Array, 'cy_dim i'], n_coords: int, ambient: tuple, k_moduli: Array = None, cdtype: DTypeLike = np.complex64)</code>","text":"<p>Returns ambient Fubini-Study metric for a CICY in product of projective spaces pulled back by the inclusion map \\(\\iota: X \\hookrightarrow \\mathbb{P}^{n_1} \\times \\cdots \\times \\mathbb{P}^{n_K}\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>2*(n+1) real homogeneous coords at which metric is evaluated. Shape [i].</p> required <code>pullbacks</code> <code>array_like</code> <p>Pullback tensor from ambient to projective variety.</p> required <code>n_coords</code> <code>int</code> <p>Dimension of ambient combined projective space.</p> required <code>ambient</code> <code>tuple</code> <p>Dimension of each projective space factor.</p> required <code>k_moduli</code> <code>(array_like, optinal)</code> <p>Kahler moduli for each projective space factor.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>g_FS_pb</code> <code>array_like</code> <p>Hermitian metric pulled back to \\(X\\) in local coordinates, \\(g_{\\mu \\bar{\\nu}}\\). Shape [i,j].</p> <p>Warning</p> <p>Note the returned metric is expressed in homogeneous coordinates and will not be of full rank.</p>"},{"location":"api/fubini_study/#cymyc.fubini_study.fubini_study_inverse","title":"<code>fubini_study_inverse(p: Float[Array, i], cdtype: DTypeLike = np.complex64)</code>","text":"<p>Returns analytic inverse in inhomogeneous coords using the Woodbury matrix identity.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2*n real inhomogeneous coords at which metric is evaluated. Shape [i].</p> required <p>Returns:</p> Name Type Description <code>g_FS_inv</code> <code>array_like</code> <p>Inverse of Hermitian metric in inhomogeneous coordinates. Shape [i,j]</p>"},{"location":"api/harmonic/","title":"Harmonic","text":""},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull","title":"<code>cymyc.approx.harmonic.HarmonicFull</code>","text":"<p>               Bases: <code>Harmonic</code></p>"},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull.__init__","title":"<code>__init__(cy_dim: int, monomials: List[np.array], ambient: ArrayLike, deformations: List[Callable], dQdz_monomials: List[np.array], dQdz_coeffs: List[np.array], metric_fn: Callable, pb_fn: Callable, coeff_fn: Callable, psi: float)</code>","text":"<p>Approximation of harmonic one-forms for Calabi-Yaus with an arbitrary number of complex  structure moduli. Note the methods vectorise over all possible complex structure deformations.</p> <p>Parameters:</p> Name Type Description Default <code>cy_dim</code> <code>int</code> <p>Dimension of Calabi-Yau manifold.</p> required <code>monomials</code> <code>List[array]</code> <p>List of defining monomials.</p> required <code>ambient</code> <code>array_like</code> <p>Dimensions of the ambient space factors.</p> required <code>deformations</code> <code>List[Callable]</code> <p>List of functions representing complex structure deformations.</p> required <code>dQdz_monomials</code> <code>List[array]</code> <p>List of monomials corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <code>dQdz_coeffs</code> <code>List[array]</code> <p>List of coefficients corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <code>metric_fn</code> <code>Callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <code>pb_fn</code> <code>Callable</code> <p>Function computing pullback matrices from ambient space to projective variety.</p> required <code>coeff_fn</code> <code>Callable</code> <p>Function returning polynomial coefficients at given point in moduli space.</p> required <code>psi</code> <code>float</code> <p>Complex structure parameter psi.</p> required See also <p>cymyc.moduli.wp.WP</p>"},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull.__call__","title":"<code>__call__(p: Float[Array, i], params: Mapping[str, Array]) -&gt; Complex[Array, 'h_21 cy_dim cy_dim']</code>","text":"<p>Constructs all harmonic representatives by \\(\\overline{\\partial}\\)-exact correction to a representative from the \\(H^{0,1}\\) Dolbeault cohomology, \\(\\xi\\);</p> \\[  \\eta = \\xi + \\overline{\\partial} \\theta~. \\] <p>Here \\(\\theta\\) is taken to be a linear combination of a basis of sections of \\(V\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>2 * <code>complex_dim</code> real coords on \\(X\\).</p> required <code>params</code> <code>Mapping[str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required"},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull.codifferential_eta","title":"<code>codifferential_eta(p: Float[Array, i], pullbacks: Complex[Array, 'cy_dim i'], g_pred: Complex[Array, 'dim dim'], params: Mapping[str, Array]) -&gt; Complex[Array, 'h_21 cy_dim']</code>","text":"<p>Computes codifferential of \\(\\alpha \\in H^{(0,1)}(X; T_X)\\) with respect to the given metric. This is a smooth section of the holomorphic tangent bundle, \\(\\bar{\\partial}^{\\dagger} \\eta \\in \\Gamma(T_X)\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>2 * <code>complex_dim</code> real coords on \\(X\\).</p> required <code>pullbacks</code> <code>Complex[Array, 'cy_dim i']</code> <p>Pullback matrices from ambient to projective variety.</p> required <code>g_pred</code> <code> Complex[Array, \"dim dim\"]</code> <p>Predicted metric \\(g_{\\mu \\overline{\\nu}}\\) in local coordinates.</p> required <code>params</code> <code>Mapping[str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required <p>Returns:</p> Name Type Description <code>codiff</code> <code>Complex[Array, 'h_21 cy_dim']</code> <p>Section of tangent bundle.</p>"},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull.wp_metric_harmonic","title":"<code>wp_metric_harmonic(data: Tuple[ArrayLike, ArrayLike, ArrayLike], eta: Complex[Array, 'h_21 cy_dim cy_dim']) -&gt; Complex[Array, 'h_21 h_21']</code>","text":"<p>Takes in harmonic one-form <code>eta</code> and forms interior product with the holomorphic form \\(\\Omega\\), to yield Weil-Petersson metric via cup product,</p> \\[  \\mathcal{G}_{a\\overline{b}} \\propto \\int_X \\iota_{\\eta_a} \\Omega \\wedge \\overline{\\iota_{\\eta_b} \\Omega}~. \\] <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tuple[ArrayLike, ArrayLike, ArrayLike]</code> <p>Tuple containing input points, integration weights and canonical volume form \\(\\Omega \\wedge \\bar{\\Omega}\\) in local coords.</p> required <code>eta</code> <code>Complex[Array, 'h_21 cy_dim cy_dim']</code> <p>Harmonic representative \\(\\eta\\).</p> required <p>Returns:</p> Type Description <code>Complex[Array, 'h_21 h_21']</code> <p>Weil-Petersson metric.</p>"},{"location":"api/harmonic/#cymyc.approx.harmonic.HarmonicFull.inner_product_Hodge","title":"<code>inner_product_Hodge(data: Tuple[ArrayLike, ArrayLike, ArrayLike], eta: Complex[Array, 'h_21 cy_dim cy_dim'], g_pred: Complex[Array, 'cy_dim cy_dim']) -&gt; Complex[Array, 'h_21 h_21']</code>  <code>staticmethod</code>","text":"<p>Hodge star inner product between harmonic forms <code>eta</code> parameterising moduli tangent directions to yield Weil-Petersson metric,</p> \\[  \\mathcal{G}_{a\\overline{b}} \\propto \\int_X \\eta_a \\wedge \\overline{\\star}_g \\eta_b~. \\] <p>This should agree with the cup product calculation provided the Ricci-flat metric is used.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tuple[ArrayLike, ArrayLike, ArrayLike]</code> <p>Tuple containing input points, integration weights and canonical volume form \\(\\Omega \\wedge \\bar{\\Omega}\\) in local coords.</p> required <code>eta</code> <code>Complex[Array, 'h_21 cy_dim cy_dim']</code> <p>Harmonic representative \\(\\eta\\).</p> required <code>g_pred</code> <code>Complex[Array, 'cy_dim cy_dim']</code> <p>Approximate Ricci-flat metric in local coords.</p> required <p>Returns:</p> Type Description <code>Complex[Array, 'h_21 h_21']</code> <p>Weil-Petersson metric.</p>"},{"location":"api/losses/","title":"Losses","text":""},{"location":"api/losses/#cymyc.approx.losses","title":"<code>cymyc.approx.losses</code>","text":"<p>Objective functions and diagnostics for approximation of metrics of vanishing Ricci curvature on Calabi-Yaus.</p>"},{"location":"api/losses/#cymyc.approx.losses.monge_ampere_loss","title":"<code>monge_ampere_loss(g_pred: Complex[Array, 'cy_dim cy_dim'], dVol_Omega: Float[Array, ''], kappa: float = 1.0, norm_order: float = 1.0) -&gt; jnp.ndarray</code>","text":"<p>Computes the integrand of the Monge-Amp\u00e8re loss,</p> \\[ \\mathcal{L}_{\\textsf{MA}} := \\int_X \\left\\Vert 1 - \\frac{1}{\\kappa} \\frac{\\det g}{\\Omega \\wedge \\overline{\\Omega}} \\right\\Vert^p d\\mu_{\\Omega}~. \\] <p>This enforces the condition that \\(\\omega^n \\propto \\Omega \\wedge \\bar{\\Omega}\\) up to some constant \\(\\kappa \\in \\mathbb{C}\\), which is a consequence of Ricci-flatness. </p> <p>Parameters:</p> Name Type Description Default <code>g_pred</code> <code> Complex[Array, \"dim dim\"]</code> <p>Predicted metric \\(g_{\\mu \\overline{\\nu}}\\) in local coordinates.</p> required <code>dVol_Omega</code> <code>Float[Array, '']</code> <p>\\(\\Omega \\wedge \\bar{\\Omega}\\) in local coordinates.</p> required <code>kappa</code> <code>float</code> <p>Proportionality constant between the canonical volume form and volume form induced by <code>g_pred</code>.</p> <code>1.0</code> <code>norm_order</code> <code>float</code> <p>Order of norm of loss, by default 1.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed Monge-Amp\u00e8re loss.</p> Notes <p>The parameter \\(\\kappa \\in \\mathbb{C}\\) denotes the constant of proportionality between \\(\\Omega \\wedge \\overline{\\Omega}\\)  and the volume form \\(\\bigwedge^n \\tilde{\\omega}\\) induced by the approximate K\u00e4hler form \\(\\tilde{\\omega}\\). In general, $$ \\bigwedge^n \\omega = h(z) \\, \\Omega \\wedge \\overline{\\Omega} ~,$$ for some holomorphic function \\(h\\), but \\(h\\) is constant for the Ricci-flat Kaehler form. Supply this if this is known  beforehand, e.g. for an ansatz which remains cohomologous to some known known reference metric.</p>"},{"location":"api/losses/#cymyc.approx.losses.ricci_tensor_loss","title":"<code>ricci_tensor_loss(p: Float[Array, i], metric_fn: Callable[[Array], Array], pullbacks: Complex[Array, 'cy_dim i'] = None, ricci_scalar_out: bool = False, norm_order: float = None) -&gt; Union[jnp.ndarray, Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]]</code>","text":"<p>Computes the norm of the Ricci tensor, in local coordinates. Here we use the fact that the Ricci curvature on a K\u00e4hler manifold is computable as, $$ \\textsf{Ric} = \\partial \\overline{\\partial} \\log \\det g_{\\mu \\bar{\\nu}}~. $$</p> <p>The Ricci tensor loss is then given by \\(\\int_X \\left\\Vert \\textsf{Ric} \\right\\Vert^p d\\mu_{\\Omega}\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Shape [i].</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <code>pullbacks</code> <code>array_like</code> <p>Pullback matrices from ambient to projective variety. If supplied, computes Ricci curvature on variety.</p> <code>None</code> <code>ricci_scalar_out</code> <code>bool</code> <p>Toggle to output Ricci scalar, default False.</p> <code>False</code> <code>norm_order</code> <code>Optional[float]</code> <p>Order of the norm, default None (corresponding to 2-norm).</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tuple[ndarray, ndarray]]</code> <p>Computed Ricci tensor loss, and optionally Ricci scalar.</p> See Also <p>curvature.ricci_form_kahler, curvature.ricci_tensor_kahler.</p>"},{"location":"api/losses/#cymyc.approx.losses.kahler_loss","title":"<code>kahler_loss(p: Float[Array, i], pullbacks: Complex[Array, 'cy_dim i'], metric_fn: Callable[[Array], Array], norm_order: float = 2) -&gt; jnp.ndarray</code>","text":"<p>Computes the integrand of the condition arising from the closedness of the  K\u00e4hler form \\(\\omega\\), $$ d\\omega = 0 \\implies g_{\\mu \\overline{\\nu}, \\rho} = g_{\\rho \\overline{\\nu}, \\mu}~, $$ with a similar condition for the antiholomorphic derivative. See Nakahara (8.82),  page 331 for more details. Note this should be exactly zero  for the FS metric + {exact correction}!</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array_like</code> <p>2 * <code>complex_dim</code> real coordinates at which <code>metric_fn</code> is evaluated. Shape [i].</p> required <code>pullbacks</code> <code>array_like</code> <p>Pullback matrices from ambient to projective variety.</p> required <code>metric_fn</code> <code>callable</code> <p>Function representing the metric tensor in local coordinates \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <code>norm_order</code> <code>float</code> <p>Order of norm, by default 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed K\u00e4hler loss.</p>"},{"location":"api/losses/#cymyc.approx.losses.volume_loss","title":"<code>volume_loss(data: Tuple[ArrayLike, ArrayLike, ArrayLike], g_FS_pb: jnp.ndarray, g_pred: jnp.ndarray, norm_order: float = 1) -&gt; jnp.ndarray</code>","text":"<p>Computes the discrepancy between the volume computed using the respective  volume forms constructed from the Fubini-Study metric and predicted metric. As the  corresponding K\u00e4hler forms are cohomologous, this should be zero.</p> \\[     \\mathcal{L}_{\\text{vol}} = \\left\\Vert \\textsf{vol}_{\\text{FS}} - \\textsf{vol}_{\\text{CY}} \\right\\Vert^p~,      \\quad \\textsf{vol}_g := \\int_X d^nx \\, \\det g~. \\] <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tuple[ArrayLike, ArrayLike, ArrayLike]</code> <p>Tuple containing input points, integration weights and canonical volume form \\(\\Omega \\wedge \\bar{\\Omega}\\) in local coords.</p> required <code>g_FS_pb</code> <code>ndarray</code> <p>Pullback of the Fubini-Study metric.</p> required <code>g_pred</code> <code>ndarray</code> <p>Predicted metric in local coordinates.</p> required <code>norm_order</code> <code>float</code> <p>Order of norm, default 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed volume loss.</p>"},{"location":"api/losses/#cymyc.approx.losses.objective_function","title":"<code>objective_function(data: Tuple[ArrayLike, ArrayLike, ArrayLike], params: Mapping[str, Array], metric_fn: Callable[[ArrayLike], jnp.ndarray], kappa: Optional[float] = None) -&gt; jnp.ndarray</code>","text":"<p>Default objective function for optimisation of Ricci-flat metrics, using only the Monge-Amp\u00e8re loss.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tuple[ArrayLike, ArrayLike, ArrayLike]</code> <p>Tuple containing input points, integration weights, and canonical volume form \\(\\Omega \\wedge \\bar{\\Omega}\\) in local coordinates.</p> required <code>params</code> <code>Mapping[Str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required <code>metric_fn</code> <code>Callable[[ArrayLike], ndarray]</code> <p>Function representing metric tensor in local coordinates,  \\(g : \\mathbb{R}^m -&gt; \\mathbb{C}^{a,b...}\\).</p> required <code>kappa</code> <code>float</code> <p>Proportionality constant between the canonical volume form and volume form induced by approximate metric.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed objective function value.</p>"},{"location":"api/losses/#cymyc.approx.losses.ma_proportionality","title":"<code>ma_proportionality(p, weights, config)</code>","text":"<p>Calculates proportionality constant between the rival volume forms \\(\\Omega \\wedge \\bar{\\Omega}\\) and \\(\\omega^n\\).</p>"},{"location":"api/models/","title":"Models","text":""},{"location":"api/models/#cymyc.approx.models","title":"<code>cymyc.approx.models</code>","text":"<p>Model architectures for approximations of tensor fields on manifolds. The idea behind  the form of each ansatz is that:</p> <ol> <li>The tensor field is parameterised using a single (possibly vector-valued) function, \\(\\phi \\in C^{\\infty}(X)\\).</li> <li>The resulting tensor field should be globally defined over the manifold.</li> </ol> <p>(2.) basically means that the local representation of the tensor field in each coordinate chart should glue  together coherently. This particularly important for manifolds with a nontrivial topology - one appears to obtain nonsensical answers for downstream predictions if this is not respected.</p> <p>The <code>flax</code> library is used here to define the models, but this is interchangable with any library or framework. As idiomatic jax is functional, the model definitions are kept separate from the parameters.  During the forward pass, the parameters are passed separately as a dictionary to the <code>apply</code> method of  the model.</p> <p>There are multiple routes to add new architectures for approximation of various tensor fields. The simplest  one, keeping in line with the logic in the models module, is to add:</p> <ol> <li>A Flax module describing  the sequence of operations defined by your architecture. <pre><code>import jax.numpy as jnp\nfrom flax import linen as nn\n\nclass MyAnsatz(nn.Module):\n\n@nn.compact\ndef __call__(self, local_coords):\n    p = local_coords\n    p_bar = jnp.conjugate(p)\n    p_norm_sq = jnp.sum(p * p_bar)\n    return jnp.outer(p, p_bar) / p_norm_sq\n</code></pre></li> <li>A pure function which accepts a pytree of parameters for the model and executes the computation by  invoking the <code>.apply</code> method of the module you defined above. <pre><code>def ansatz_fun(p, params, *args):\n    p = ...  # some logic\n    model = MyAnsatz(*args)  # model constructor\n    return model.apply({'params': params}, p)\n</code></pre></li> </ol>"},{"location":"api/models/#cymyc.approx.models.LearnedVector_spectral_nn","title":"<code>LearnedVector_spectral_nn</code>","text":"<p>               Bases: <code>Module</code></p> <p>Spectral network implementation for hypersurfaces embedded in \\(\\mathbb{P}^n\\). The model defined here is a simple feedforward network with a spectral embedding layer at the input, which converts points expressed in homogeneous coordinates to a \\(\\mathbb{C}^*\\)-invariant matrix representation. The resulting parameterised function  is globally defined over \\(X\\) - one may then construct various ansatze off this. For details see arxiv:2211.09801.</p> <p>Attributes:</p> Name Type Description <code>dim</code> <code>int</code> <p>Dimension of projective space + 1.</p> <code>ambient</code> <code>Sequence[int]</code> <p>Dimensions of the ambient space factors.</p> <code>n_units</code> <code>(Sequence[int], optional)</code> <p>Number of units in each layer, by default (64, 64, 64).</p> <code>n_out</code> <code>(int, optional)</code> <p>Number of output features, by default 1.</p> <code>use_spectral_embedding</code> <code>(bool, optional)</code> <p>Whether to use spectral embedding, default True.</p> <code>activation</code> <code>(Callable[[ndarray], ndarray], optional)</code> <p>Nonlinearity between each layer, default nn.gelu.</p> <code>cy_dim</code> <code>(int, optional)</code> <p>Dimension of the complex projective space, default 3.</p>"},{"location":"api/models/#cymyc.approx.models.LearnedVector_spectral_nn.spectral_layer","title":"<code>spectral_layer(x: Float[Array, i], x_dim: int) -&gt; Array</code>","text":"<p>Converts homogeneous \\([z_0 : ... : z_n]\\) coords in \\(\\mathbb{P}^n\\)  into the first-order basis of eigenfunctions of the Laplacian in projective space, whose generic form is \\(z_i \\bar{z}_j / \\sum z_k \\bar{z}_k\\).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates.</p> required <code>x_dim</code> <code>int</code> <p>Dimension of the input array.</p> required <p>Returns:</p> Type Description <code>Complex[Array, i * i + 1 // 2]</code> <p>First-order basis of eigenfunctions of the Laplacian as a vector.</p>"},{"location":"api/models/#cymyc.approx.models.LearnedVector_spectral_nn.__call__","title":"<code>__call__(x: Float[Array, i]) -&gt; Array</code>","text":"<p>Spectral NN forward pass for hypersurfaces embedded in a single projective space factor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates.</p> required <p>Returns:</p> Type Description <code>Complex[Array, n_out]</code> <p>Output of vector-valued function.</p>"},{"location":"api/models/#cymyc.approx.models.LearnedVector_spectral_nn_CICY","title":"<code>LearnedVector_spectral_nn_CICY</code>","text":"<p>               Bases: <code>LearnedVector_spectral_nn</code></p> <p>Spectral network implementation for manifolds embedded in a product of projective space factors, \\({P}^{n_1} \\times \\cdots \\times \\mathbb{P}^{n_K}\\).</p>"},{"location":"api/models/#cymyc.approx.models.LearnedVector_spectral_nn_CICY.__call__","title":"<code>__call__(x: Float[Array, i]) -&gt; Array</code>","text":"<p>Spectral NN forward pass for complete intersection manifolds in a product of projective spaces. The spectral layer converts the coordinates for each  projective space to its respective \\(\\mathbb{C}^*\\)-invariant matrix representation, and concatenates the results.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates, local coordinates for each projective space factor are listed consecutively in the input array.</p> required <p>Returns:</p> Type Description <code>Complex[Array, n_out]</code> <p>Output of vector-valued function.</p>"},{"location":"api/models/#cymyc.approx.models.CoeffNetwork_spectral_nn_CICY","title":"<code>CoeffNetwork_spectral_nn_CICY</code>","text":"<p>               Bases: <code>LearnedVector_spectral_nn</code></p> <p>Spectral network parameterising the coefficients of a linear combination of a basis of sections for the holomorphic bundle \\(V \\rightarrow X\\). The sections are globally defined  by construction, hence the linear combination is a global section of \\(V\\), parameterised by a neural network. Schematically,</p> \\[ s:= \\sum_I \\psi_I^{(\\textsf{NN})} \\cdot \\mathbf{e}^I~. \\] <p>Where summation over the multi-index \\(I\\) denotes contraction of appropriate tensor indices. Here the network specialises to the case of \\(V=T_X\\), the standard embedding, but interchangeable with any other bundle \\(V \\rightarrow X\\) by subclassing and modifying the shapes of the coefficients.</p> <p>The case of multiple parameterised sections \\(s^{(k)} \\in \\Gamma(V)\\) modelled is handled  by the <code>h_21</code> parameter - this sets the number of coefficients output by the network.</p> <p>Inherits from <code>LearnedVector_spectral_nn</code>.</p> <p>Attributes:</p> Name Type Description <code>h_21</code> <code>int</code> <p>Dimension of complex structure moduli space - controls the number of sections learnt.</p>"},{"location":"api/models/#cymyc.approx.models.CoeffNetwork_spectral_nn_CICY.__call__","title":"<code>__call__(x: Float[Array, i]) -&gt; Array</code>","text":"<p>Forward pass for coefficients, modelled as vector-valued functions on \\(X\\). </p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates, local coordinates for each projective space factor are listed consecutively in the input array.</p> required <p>Returns:</p> Type Description <code>Complex[Array, n_out]</code> <p>Output of vector-valued function.</p>"},{"location":"api/models/#cymyc.approx.models.phi_head","title":"<code>phi_head(p: Float[Array, i], params: Mapping[str, Array], n_hyper: int, ambient: Sequence[int], n_out: int = 1, spectral: bool = True, activation: Callable[[jnp.ndarray], jnp.ndarray] = nn.gelu) -&gt; Complex[Array, n_out]</code>","text":"<p>Wrapper to feed parameters into forward pass for \\(\\phi\\)-component in  the <code>ddbar_phi_model</code>.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates.</p> required <code>params</code> <code>Mapping[Str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required <code>n_hyper</code> <code>int</code> <p>Number of defining equations of the complete intersection.</p> required <code>ambient</code> <code>Sequence[int]</code> <p>Sequence representing the ambient space dimensions.</p> required <code>n_out</code> <code>int</code> <p>Dimension of output vector, default 1.</p> <code>1</code> <code>spectral</code> <code>bool</code> <p>Toggles spectral embedding, default True.</p> <code>True</code> <code>activation</code> <code>Callable[[ndarray], ndarray]</code> <p>Activation function, default nn.gelu.</p> <code>gelu</code> <p>Returns:</p> Type Description <code>Complex[Array, n_out]</code> <p>Output of vector-valued function.</p>"},{"location":"api/models/#cymyc.approx.models.ddbar_phi_model","title":"<code>ddbar_phi_model(p: Float[Array, i], params: Mapping[str, Array], g_ref_fn: Callable[[ArrayLike], jnp.ndarray], g_correction_fn: Callable[[ArrayLike], jnp.ndarray]) -&gt; jnp.ndarray</code>","text":"<p>Returns metric on \\(X\\) under pullback from ambient space as an \\(\\partial \\bar{\\partial}\\)-exact correction to the reference Fubini-Study metric in the desired K\u00e4hler class, $$  \\tilde{g} := g_{\\text{ref}} + \\partial \\overline{\\partial} \\phi; \\quad \\phi \\in C^{\\infty}(X)~. $$ Generates pullbacks on the fly. </p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates.</p> required <code>params</code> <code>Mapping[Str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required <code>g_ref_fn</code> <code>Callable[[ndarray], ndarray]</code> <p>Function representing reference Fubini-Study metric in local coordinates.</p> required <code>g_correction_fn</code> <code>Callable[[ndarray], ndarray]</code> <p>Function \\(\\phi \\in C^{\\infty}(X)\\) which generates the \\(\\partial \\bar{\\partial}\\)-exact  correction to the reference metric.</p> required"},{"location":"api/models/#cymyc.approx.models.coeff_head","title":"<code>coeff_head(p: Float[Array, i], params: Mapping[str, Array], n_homo_coords: int, ambient: Sequence[int], h_21: int = 1, activation: Callable[[jnp.ndarray], jnp.ndarray] = nn.gelu) -&gt; jnp.ndarray</code>","text":"<p>Wrapper to feed parameters into forward pass for section coefficient network.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, i]</code> <p>Input array of homogeneous coordinates.</p> required <code>params</code> <code>Mapping[Str, Array]</code> <p>Model parameters stored as a dictionary - keys are the module names registered upon initialisation and values are the parameter values.</p> required <code>n_homo_coords</code> <code>int</code> <p>Number of homogeneous coordinates.</p> required <code>ambient</code> <code>Sequence[int]</code> <p>Sequence representing the ambient space dimensions.</p> required <code>h_21</code> <code>int</code> <p>Number of sections learnt / harmonic \\((0,1)\\) forms on \\(X\\). This controls the size of the coefficient network.</p> <code>1</code> <code>activation</code> <code>Callable[[ndarray], ndarray]</code> <p>Activation function, default nn.gelu.</p> <code>gelu</code>"},{"location":"api/moduli_space/","title":"Moduli space","text":""},{"location":"api/moduli_space/#cymyc.moduli.wp.WP_full","title":"<code>cymyc.moduli.wp.WP_full</code>","text":"<p>               Bases: <code>WP</code></p>"},{"location":"api/moduli_space/#cymyc.moduli.wp.WP_full.__init__","title":"<code>__init__(cy_dim: int, monomials: List[np.array], ambient: ArrayLike, deformations: List[Callable])</code>","text":"<p>Base class for geometric computations over complex structure moduli space.</p> <p>Parameters:</p> Name Type Description Default <code>cy_dim</code> <code>int</code> <p>Dimension of Calabi-Yau manifold.</p> required <code>monomials</code> <code>List[array]</code> <p>List of defining monomials.</p> required <code>ambient</code> <code>ArrayLike</code> <p>Dimensions of the ambient space factors.</p> required <code>deformations</code> <code>List[Callable]</code> <p>List of functions representing complex structure deformations.</p> required Notes <p>Here the <code>deformations</code> parameter is a list of polynomial deformations corresponding  to independent tangent vectors of the complex structure moduli space - there should be  \\(h^{(2,1)}\\) deformations to construct the complete moduli space metric. For example, for  the deformation family of the intersection of two cubics in \\(\\mathbb{P}^5\\),</p> \\[ B_{\\psi} = \\left\\{\\begin{array}{c}Z_0^3 + Z_1^3 + Z_2^3 - 3 \\psi Z_3 Z_4 Z_5 = 0\\\\ Z_3^3 + Z_4^3 + Z_5^3 - 3 \\psi Z_0 Z_1 Z_2 = 0\\end{array} \\, : \\, \\psi \\in \\mathbb{C}\\right\\} \\subset \\mathbb{P}^5~. \\] <p>The single complex structure moduli direction corresponds to the trilinear polynomial deformations above,  and we can write down this deformation explicitly:</p> <pre><code>def X33_deformation(p, precision=np.complex128):\n    d1 = jnp.einsum(\"...a,aj-&gt;...j\", jnp.expand_dims(p[3]*p[4]*p[5], axis=-1),\n                    jnp.asarray([[-3.,0.]], precision))\n    d2 = jnp.einsum(\"...a,aj-&gt;...j\", jnp.expand_dims(p[0]*p[1]*p[2], axis=-1),\n                    jnp.asarray([[0.,-3.]], precision))\n    return d1 + d2\n</code></pre>"},{"location":"api/moduli_space/#cymyc.moduli.wp.WP_full.compute_wp_metric_complete","title":"<code>compute_wp_metric_complete(p: Float[Array, '... i'], dQdz_monomials: List[np.array], dQdz_coeffs: List[np.array]) -&gt; Complex[Array, 'h_21 h_21']</code>","text":"<p>Computes the full \\(h^{2,1} \\times h^{2,1}\\) metric \\(\\mathcal{G}_{a\\overline{b}}\\) over complex structure moduli space  (the Weil-Petersson metric). This is obtained by Monte Carlo integration over the fibres of the deformation  family. Letting \\((-,-)\\) denote the standard intersection pairing on \\(H^{p,q}_{\\overline{\\partial}}(X)\\) with \\(p+q=n\\):</p> \\[ \\begin{align} \\mathcal{G}_{a\\bar{b}} = \\left(\\frac{d\\Omega_t}{d  t^a}, \\frac{d\\Omega_t}{d t^b}\\right)\\bigg\\vert_{t_0} - \\frac{1}{(\\Omega,\\Omega)}\\left(\\Omega, \\frac{d\\Omega_t}{d t^a}\\right)\\bigg\\vert_{t_0}  \\cdot  \\overline{\\left(\\Omega, \\frac{d\\Omega_t}{d t^b}\\right)}\\bigg\\vert_{t_0}\\,. \\end{align} \\] <p>Note that the number of integration points required is exponential in the dimension of moduli space. See the article arxiv:2401.15078 and Mirror symmetry, Mori,  eq. (6.1). for more details. NB: Don't <code>vmap</code> this.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, '... i']</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Note batch indices.</p> required <code>dQdz_monomials</code> <code>List[array]</code> <p>List of monomials corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <code>dQdz_coeffs</code> <code>List[array]</code> <p>List of coefficients corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <p>Returns:</p> Name Type Description <code>G_wp</code> <code>Complex[Array, 'h_21 h_21']</code> <p>Weil-Petersson metric at the point <code>p</code> in complex structure moduli space.</p> Notes <p>Owing to vectorisation, this is significantly more efficient than computing individual components separately.</p>"},{"location":"api/moduli_space/#cymyc.moduli.wp.WP_full.kappa_complete","title":"<code>kappa_complete(p: Float[Array, '... i'], dQdz_monomials: List[np.array], dQdz_coeffs: List[np.array], weights=None, pb=None, output_variance: bool = False) -&gt; Complex[Array, 'h_21 h_21 h_21']</code>","text":"<p>Computes full set of \\(h^{2,1} \\times h^{2,1} \\times h^{2,1}\\) Yukawa couplings (three-point function) for a CY threefold.  On a fibre \\(X_s\\) of the deformation family, where \\(s\\) parameterises the moduli space, the \\((a,b,c)\\) component is given by,</p> \\[\\kappa_{abc} = \\int_{X_s} \\Omega \\wedge \\left.\\frac{d \\Omega}{ds^a ds^b ds^c} \\right\\vert_{s=0}.\\] <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, '... i']</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Note batch indices.</p> required <code>dQdz_monomials</code> <code>List[array]</code> <p>List of monomials corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <code>dQdz_coeffs</code> <code>List[array]</code> <p>List of coefficients corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <p>Returns:</p> Name Type Description <code>int_kappa_abc</code> <code>Complex[Array, 'h_21 h_21 h_21']</code> <p>Yukawa couplings at given point in complex structure moduli space.</p> Notes <p>Owing to vectorisation, this is significantly more efficient than computing individual couplings separately.</p>"},{"location":"api/moduli_space/#cymyc.moduli.wp.WP_full.kahler_potential","title":"<code>kahler_potential(p: Float[Array, '... i'], dQdz_monomials: List[np.array], dQdz_coeffs: List[np.array]) -&gt; Complex[Array, ...]</code>","text":"<p>Computes K\u00e4hler potential for moduli space metric at point \\(t\\) in moduli space. $$ \\mathcal{K}(t, \\overline{t}) = - \\log \\int_{X_t} \\Omega_t \\wedge \\overline{\\Omega}_t.~.$$</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Float[Array, '... i']</code> <p>2 * <code>complex_dim</code> real coords at which <code>fun</code> is evaluated. Note batch indices.</p> required <code>dQdz_monomials</code> <code>List[array]</code> <p>List of monomials corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <code>dQdz_coeffs</code> <code>List[array]</code> <p>List of coefficients corresponding to polynomial Jacobian \\(dQ/dz\\).</p> required <p>Returns:</p> Name Type Description <code>K</code> <code>Complex[Array, ...]</code> <p>K\u00e4hler potential at given point in complex structure moduli space.</p>"},{"location":"examples/cs_moduli/","title":"Cs moduli","text":"<p>CS moduli</p>"},{"location":"examples/cs_moduli/#mathbbp533-mirror","title":"\\(\\mathbb{P}^5[3,3]\\) mirror","text":"<p>Intersection of two cubics in \\(\\mathbb{P}^5\\). Need to solve geodesic equation</p> \\[ \\frac{\\mathrm{d}^2 \\gamma}{\\mathrm{d} t^2} + \\Gamma^{a}_{bc} \\frac{\\mathrm{d}\\gamma^b}{\\mathrm{d}t}\\frac{\\mathrm{d}\\gamma^c}{\\mathrm{d}t} = 0~. \\] <p>Plot geodesics and stuff.</p>"},{"location":"examples/cs_moduli/#tian-yau-quotient","title":"Tian-Yau quotient","text":"<p>Ditto.</p>"},{"location":"examples/curvature/","title":"Curvature","text":"<pre><code>import jax\nfrom jax import random, jit, vmap\nimport jax.numpy as jnp\n\nimport os, time\nimport numpy as np\n\nfrom functools import partial\n\njax.config.update(\"jax_enable_x64\", True)\n</code></pre> <pre><code>from cymyc.utils import math_utils\n\nambient_dim = 10\nN = 10\nseed = int(time.time()) # 42\nrng = random.PRNGKey(seed)\nrng, _rng = random.split(rng)\n\ndef S2np1_uniform(key, n_p, n, dtype=np.float64):\n    \"\"\"\n    Sample `n_p` points uniformly on the unit sphere $S^{2n+1}$, treated as CP^n\n    \"\"\"\n    # return random.uniform(key, (n,))*jnp.pi, random.uniform(key, (n,)) * 2 * jnp.pi\n    x = random.normal(key, shape=(n_p, 2*(n+1)), dtype=dtype)\n    x_norm = x / jnp.linalg.norm(x, axis=1, keepdims=True)\n    sample = math_utils.to_complex(x_norm.reshape(-1, n+1, 2))\n\n    return jnp.squeeze(sample)\n</code></pre> <pre><code>Z = S2np1_uniform(_rng, N, ambient_dim)\nZ\n</code></pre> <pre>\n<code>Array([[ 0.02736979-0.22389161j,  0.25014222-0.34731673j,\n        -0.00753072-0.29925316j,  0.25562023+0.29378541j,\n        -0.05679859-0.20567943j,  0.04690634+0.12982876j,\n         0.15532516+0.14336839j,  0.20046198-0.38581777j,\n        -0.26256972+0.28638481j, -0.12090856-0.13025232j,\n         0.00636905+0.20921725j],\n       [ 0.00833806-0.12314272j,  0.33281516+0.1516645j ,\n        -0.1483373 -0.16471397j, -0.1052314 +0.2249917j ,\n        -0.08208166-0.10561346j,  0.49581376-0.1674636j ,\n        -0.00324378-0.21552658j,  0.24867794-0.19161808j,\n        -0.14643599+0.17849217j,  0.41380261-0.19468098j,\n        -0.17593772-0.09995519j],\n       [ 0.27014354+0.43684002j, -0.20377776-0.11443033j,\n        -0.21397595-0.00243355j,  0.1063651 +0.17664001j,\n        -0.41157039-0.09987887j,  0.07792631+0.01783108j,\n        -0.1407708 -0.14530487j, -0.00628455-0.20375251j,\n        -0.26621185+0.2402969j , -0.12324527-0.3368604j ,\n        -0.08962662+0.24437101j],\n       [ 0.298288  +0.0090613j , -0.09293679+0.12098218j,\n         0.15873836+0.30437709j,  0.09010836+0.24775444j,\n         0.12491493+0.0599167j ,  0.06105556+0.02011806j,\n        -0.06107647-0.08125648j,  0.39116699+0.09845587j,\n        -0.06334902+0.10514544j, -0.37315632+0.03532256j,\n         0.1744366 -0.5638871j ],\n       [-0.03686343-0.11681997j, -0.04676194-0.14645691j,\n         0.16080594-0.16616212j,  0.16180508+0.22286588j,\n        -0.20503923+0.14494859j,  0.2959065 -0.2568473j ,\n         0.28694812-0.21742779j, -0.29545629+0.15549756j,\n        -0.43242921-0.02473469j,  0.20736562+0.35661549j,\n        -0.10635665+0.07263177j],\n       [ 0.37908512+0.22849334j,  0.012651  -0.37016357j,\n         0.22781669-0.11919621j,  0.14999072+0.33529792j,\n         0.17039864+0.07631351j,  0.31776397-0.03556206j,\n         0.22090967+0.03842842j,  0.13607875+0.32494174j,\n        -0.24973331+0.02489945j, -0.10798666-0.08427205j,\n         0.21141219-0.16717926j],\n       [ 0.1293235 +0.20853088j,  0.11784573-0.14996482j,\n        -0.26778802+0.11306106j,  0.0662057 +0.04690227j,\n         0.37957281-0.12004818j,  0.27164364+0.26007059j,\n        -0.22151153-0.03442996j,  0.10460384+0.45146498j,\n        -0.15981234-0.348539j  ,  0.08582687+0.19522458j,\n        -0.20275629-0.11746974j],\n       [ 0.2527872 +0.06671784j, -0.10444607+0.02656615j,\n         0.08960571-0.07636178j,  0.08993089-0.34046328j,\n        -0.20523979+0.51587811j, -0.33898292-0.14847849j,\n         0.17718462+0.22234663j,  0.0333801 -0.30936953j,\n         0.20401253-0.20578521j,  0.12323492-0.24393537j,\n        -0.0247256 +0.00575643j],\n       [-0.00236344-0.47434857j,  0.35553164-0.21107713j,\n         0.10827872-0.14736322j,  0.0215133 +0.04707496j,\n        -0.24504572-0.09207816j, -0.3192196 +0.02622722j,\n         0.02600101+0.03722147j, -0.21314049-0.04537127j,\n        -0.1855012 -0.37369281j, -0.31240302-0.2581296j ,\n        -0.08234807-0.04673321j],\n       [ 0.12391426-0.15099357j, -0.10282917-0.07848328j,\n         0.26018045-0.39339781j, -0.12754509+0.16708262j,\n         0.12648189-0.10537365j,  0.02287195+0.006204j  ,\n         0.0445617 -0.0977747j , -0.37106113+0.25683421j,\n        -0.13924258+0.10475447j,  0.45967485+0.29416271j,\n         0.27354486-0.18053403j]], dtype=complex128)</code>\n</pre> <p>We now use the scaling freedom in projective space to convert homogeneous coords on \\(\\mathbb{C}\\mathbb{P}^n\\), \\(\\left[z_0 : \\cdots : z_n\\right]\\) to inhomogeneous coords in some local coordinate chart where \\(z_{\\alpha}\\) nonzero, setting \\(z_{\\alpha} = 1\\) and removing it from the coordinate description,</p> \\[\\left[z_0 : \\cdots : z_n\\right] \\mapsto \\left(\\frac{z_0}{z_{\\alpha}}, \\ldots, \\frac{z_{\\alpha-1}}{z_{\\alpha}}, \\frac{z_{\\alpha+1}}{z_{\\alpha}}, \\ldots, \\frac{z_n}{z_{\\alpha}}\\right) \\triangleq \\zeta^{(\\alpha)}~. \\] <pre><code>Z, _ = math_utils.rescale(Z)\nz = vmap(math_utils._inhomogenize)(Z)\nz.shape\n</code></pre> <pre>\n<code>(10, 10)</code>\n</pre> <pre><code>def fubini_study_metric(p):\n    \"\"\"\n    Returns FS metric in CP^n evaluated at `p`.\n    Parameters\n    ----------\n        `p`     : 2*complex_dim real inhomogeneous coords at \n                  which metric matrix is evaluated. Shape [i].\n    Returns\n    ----------\n        `g`     : Hermitian metric in CP^n, $g_{ij}$. Shape [i,j].\n    \"\"\"\n\n    # Inhomogeneous coords\n    complex_dim = p.shape[-1]//2\n    zeta = jax.lax.complex(p[:complex_dim],\n                           p[complex_dim:])\n    zeta_bar = jnp.conjugate(zeta)\n    zeta_sq = 1. + jnp.sum(zeta * zeta_bar)\n\n    zeta_outer = jnp.einsum('...i,...j-&amp;gt;...ij', zeta_bar, zeta)\n\n    delta_mn = jnp.eye(complex_dim, dtype=jnp.complex64) \n\n    g_FS = jnp.divide(delta_mn * zeta_sq - zeta_outer, jnp.square(zeta_sq))\n\n    return g_FS\n</code></pre> <pre><code>p = math_utils.to_real(z)\ng_FS = vmap(fubini_study_metric)(p)\ng_FS.shape\n</code></pre> <pre>\n<code>(10, 10, 10)</code>\n</pre> <p>We can benchmark execution times with and without <code>jit</code>-compilation - note the exact speedup will depend on the hardware available. </p> <pre><code>%%timeit\n_ = vmap(fubini_study_metric)(p).block_until_ready()\n</code></pre> <pre>\n<code>6.09 ms \u00b1 271 \u03bcs per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code>\n</pre> <pre><code>%%timeit\n_ = vmap(jit(fubini_study_metric))(p).block_until_ready()\n</code></pre> <pre>\n<code>629 \u03bcs \u00b1 11.5 \u03bcs per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n</code>\n</pre> <pre><code>def fubini_study_potential(p):\n    \"\"\"\n    Returns Kahler potential associated with the FS metric\n    in CP^n evaluated at `p`.\n    Parameters\n    ----------\n        `p`        : 2*complex_dim real inhomogeneous coords at \n                     which potential is evaluated. Shape [i].\n    Returns\n    ----------\n        `phi`      : Kahler potential, real scalar. Shape [].  \n    \"\"\"\n    zeta_sq = jnp.sum(p**2)\n    return jnp.log(1. + zeta_sq)\n</code></pre> <pre><code>from cymyc import curvature\n_g_FS = vmap(curvature.del_z_bar_del_z, in_axes=(0,None))(p, fubini_study_potential)\n_g_FS.shape\n</code></pre> <pre>\n<code>(10, 10, 10)</code>\n</pre> <pre><code>jnp.allclose(g_FS, _g_FS)\n</code></pre> <pre>\n<code>Array(True, dtype=bool)</code>\n</pre> <p>Measures of curvature corresponding to a given metric tensor involve derivatives of the metric - if a function corresponding to the metric tensor is known, these may be easily computed numerically using autodiff. The most important curvature quantity is the Riemann curvature - the endomorphism-valued two-form that informs us about local curvature effects, \\(\\textsf{Riem} \\in \\Omega^2(X; \\textsf{End}(T_X))\\).</p> <p>Schematically, the curvature tensor is given by taking two derivatives of the metric tensor w.r.t. the input coordinates. \\(\\Gamma\\) below refers to the Levi-Civita connection in local coordinates,</p> \\[\\textsf{Riem} \\sim \\partial \\Gamma + \\Gamma \\cdot \\Gamma, \\quad \\Gamma \\sim g^{-1} \\partial g~.\\] <pre><code>riem = vmap(curvature.riemann_tensor_kahler, in_axes=(0,None))(p, jax.tree_util.Partial(fubini_study_metric))\n</code></pre> <p>This involves two derivatives of a potentially expensive function, but is reasonably speedy for even \\(10^4\\) points, as we can test by benchmarking - in this case the function is already <code>jit</code>-ed at definition. Note nested <code>jit</code>s are equivalent to a single <code>jit</code>.</p> <pre><code>%%timeit\nriem = vmap(curvature.riemann_tensor_kahler, in_axes=(0,None))(p, jax.tree_util.Partial(fubini_study_metric)).block_until_ready()\nriem.shape\n</code></pre> <pre>\n<code>1.54 ms \u00b1 65.2 \u03bcs per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n</code>\n</pre> <pre><code>rtk = partial(curvature.riemann_tensor_kahler, return_aux=True)\n</code></pre> <pre><code>_, riem = vmap(rtk, in_axes=(0,None))(p, jax.tree_util.Partial(fubini_study_metric))\n</code></pre> <pre><code>riem = jnp.einsum('...abcd, ...ae-&amp;gt;...becd', riem, g_FS)\nriem.shape\n</code></pre> <pre>\n<code>(10, 10, 10, 10, 10)</code>\n</pre> <pre><code>riem_lower = jnp.einsum('...ibcd, ...ia-&amp;gt;...bacd', riem, g_FS)\n</code></pre> <pre><code>jnp.allclose(riem_lower, jnp.einsum('...abcd-&amp;gt;...adcb', riem_lower))  # first equality\n</code></pre> <pre>\n<code>Array(False, dtype=bool)</code>\n</pre> <pre><code>jnp.allclose(riem_lower, jnp.einsum('...abcd-&amp;gt;...cbad', riem_lower))  # second equality\n</code></pre> <pre>\n<code>Array(True, dtype=bool)</code>\n</pre> <pre><code>jnp.allclose(riem_lower, jnp.einsum('...abcd-&amp;gt;...cdab', riem_lower))  # third equality\n</code></pre> <pre>\n<code>Array(False, dtype=bool)</code>\n</pre> <p>Complex projective space is an Einstein manifold, meaning that the Fubini-Study metric on \\(\\mathbb{P}^n\\) is proportional to the Ricci curvature. The Ricci curvature is another important measure of curvature derived from \\(\\textsf{Riem}\\), which roughly measures the degree of volume distortion relative to Euclidean space as one travels along geodesics emanating from a given point.</p> \\[\\textsf{Ric} = \\Lambda g~.\\] <p>For \\(\\mathbb{P}^n\\) the Einstein constant is \\(\\Lambda = n+1; \\textsf{Ric} = (n+1) g_{FS}\\).</p> <p>The Ricci curvature is given, in local coordinates, as the trace of the endomorphism part of the Riemann curvature tensor,</p> \\[ \\textsf{Ric}_{\\mu \\bar{\\nu}} \\triangleq \\textsf{Riem}^{\\kappa}_{\\; \\kappa \\mu \\bar{\\nu}} = \\textsf{Riem}^{\\kappa}_{\\; \\mu \\kappa \\bar{\\nu}}~.\\] <pre><code>ricci = vmap(curvature.ricci_tensor_kahler, in_axes=(0,None))(p, jax.tree_util.Partial(fubini_study_metric))\n</code></pre> <pre><code>jnp.allclose(ricci, (ambient_dim + 1) * g_FS)\n</code></pre> <pre>\n<code>Array(True, dtype=bool)</code>\n</pre> <p>This also means that the Ricci scalar, the trace of the Ricci curvature, should be, on \\(\\mathbb{P}^n\\):</p> \\[ \\textsf{R} = n(n+1)~.\\] <pre><code>jnp.einsum('...ba, ...ab', jnp.linalg.inv(g_FS), ricci)\n</code></pre> <pre>\n<code>Array([110.+8.26087339e-16j, 110.-4.13292887e-16j, 110.+6.68198714e-16j,\n       110.-6.83617305e-17j, 110.-1.03265506e-15j, 110.-1.35128649e-15j,\n       110.+7.40287060e-16j, 110.+4.10574786e-16j, 110.+1.34577413e-15j,\n       110.+1.86926177e-15j], dtype=complex128)</code>\n</pre>"},{"location":"examples/curvature/#curvature","title":"Curvature","text":"<p>In this introductory example we compute various curvature quantities from the Riemannian metric on a manifold and compare against analytically known results. Everything here should be accessible with a basic knowledge of scientific computing and differential geometry. There are two Jax-specific transformations which we explain briefly below, for more detail please see the official guides.</p> <ul> <li><code>jax.jit</code>: Short for Just-in-Time compilation, this converts Jax Python functions to an optimised sequence of primitive operations which are then passed to some hardware accelerator. The output of <code>jit</code> is another function - usually one that executes significantly faster than the Python equivalent. The price to be paid is that the program logic of a <code>jit</code>-compatible function is constrained by the compiler, so you don't want (or need) to <code>jit</code> everything.</li> <li><code>jax.vmap</code>: Short for Vectorising Map, this transforms Jax Python functions written for execution on a single array element, to one which is automatically vectorised across the specified array axes. Again, program logic of a <code>vmap</code>-compatible function is restricted.</li> </ul> <p>Jax transformations are compatible - you can <code>jit</code> a <code>vmap</code>-ed function and vice-versa. And that's pretty much all you need to know to understand this example!</p> <p>While not a dependency of the package, the example notebooks require the installation of <code>jupyter</code>, run this locally if you haven't already. <pre><code>pip install --upgrade jupyter notebook\n</code></pre></p>"},{"location":"examples/curvature/#manifold-definition-point-sampling","title":"Manifold definition / point sampling","text":"<p>The routines in this library will work for an arbitrary real or complex manifold from which points may be sampled from. In this example, we consider complex projective space \\(\\mathbb{P}^n\\). This the space of complex lines in \\(\\mathbb{C}^{n+1}\\) which pass through the origin.</p> <p>To sample from \\(\\mathbb{P}^n\\), we use the fact that every complex line intersects the unit sphere along a circle, whose \\(U(1)\\) action we mod out, \\(\\mathbb{P}^n \\simeq S^{2n+1} / U(1)\\). This means that samples from the unit sphere, appropriately complexified, give samples in homogeneous coordinates on projective space. Here we set \\(n=5\\).</p>"},{"location":"examples/curvature/#metric-definition","title":"Metric definition","text":"<p>There is a natural metric on \\(\\mathbb{P}^n\\) - the Fubini-Study metric. Viewing \\(\\mathbb{P}^n\\) as the quotient \\(S^{2n+1} / U(1)\\), the Fubini_study metric is the unique metric such that the projection \\(\\pi: S^{2n+1} \\rightarrow \\mathbb{P}^n\\) is a Riemannian submersion. In inhomogeneous coordinates,</p> \\[ g_{\\mu \\bar{\\nu}} = \\frac{1}{\\sigma}\\left( \\delta_{\\mu \\overline{\\nu}} - \\frac{\\zeta_{\\mu}\\zeta_{\\bar{\\nu}}}{\\sigma}\\right), \\quad \\sigma = 1 + \\sum_{m=1}^n \\zeta_m\\bar{\\zeta}_m~. \\] <p>The function below returns the FS metric in local coordinates. Note it requires a real input for autodiff to play nice, so we use the map </p> \\[z = (z_1, \\ldots, z_n) \\in \\mathbb{C}^n \\mapsto (\\Re(z_1), \\ldots, \\Re(z_n); \\Im(z_1), \\ldots, \\Im(z_n)) \\in \\mathbb{R}^{2n}~.\\]"},{"location":"examples/curvature/#the-kahler-potential","title":"The K\u00e4hler potential","text":"<p>\\(\\mathbb{P}^n\\) is a K\u00e4hler manifold - this imbues it with many special properties, one of them being that the metric is locally determined by a single real scalar function, the K\u00e4hler potential, \\(\\mathcal{K} \\in C^{\\infty}(\\mathbb{P}^n)\\).</p> \\[\\begin{align*} g_{\\mu \\bar{\\nu }} &amp;= \\partial_{\\mu}\\overline{\\partial}_{\\bar{\\nu}} \\mathcal{K}~, \\\\ \\mathcal{K} &amp;= \\log \\left( 1+ \\sum_{m=1}^n \\left\\vert \\zeta_m \\right\\vert^2\\right)~. \\end{align*}\\] <p>This is particularly important in the context of approximating metrics, as it allows one to reduce the problem to approximation of a single scalar function.</p>"},{"location":"examples/curvature/#riemann-tensor","title":"Riemann tensor","text":""},{"location":"examples/curvature/#first-bianchi-identity","title":"First Bianchi identity","text":"<p>We form the Riemann tensor with all indices lowered using the musical isomorphism defined by the metric. The resulting tensor satisifies the following symmetries, as a consequence of the first Bianchi identity,</p> \\[ \\textsf{Riem}_{a\\overline{b}c\\overline{d}} = \\textsf{Riem}_{a \\overline{d} c \\overline{b}} = \\textsf{Riem}_{c \\overline{b} a \\overline{d}} = \\textsf{Riem}_{c \\overline{d} a \\overline{b}}~.\\]"},{"location":"examples/curvature/#ricci-curvature","title":"Ricci curvature","text":""},{"location":"examples/harmonic/","title":"Harmonic forms","text":"<pre><code>import jax\nfrom jax import random\nimport jax.numpy as jnp\n\nimport os, time\nimport numpy as np\n\nfrom functools import partial\n\nfrom cymyc import dataloading\nfrom cymyc.utils import gen_utils as utils\n</code></pre> <pre><code>class args(object):\n    # specify training config. For more options, see `src/approx/default_config`\n    name = \"X33_demo_harmonic\"\n    learning_rate = 1e-4\n    n_epochs = 24\n    dataset = \"data/X33_demo/\"\n    metric_checkpoint = \"experiments/X33_demo/X33_demo_epoch_FIN_2024_10_28_14:28_PARAMS.pkl\" # replace this with your checkpoint\n    batch_size = 1024\n    n_units_harmonic = [64, 64, 128, 64, 42]\n\n# Override default arguments from config file with provided command line arguments\nfrom cymyc.approx.default_config import config\nconfig = utils.override_default_args(args, config)\nconfig = utils.read_metadata(config)  # load dataset metadata\n\nnp_rng = np.random.default_rng()\ndata_train, data_val, train_loader, val_loader, psi = dataloading.initialize_loaders_train(\n    np_rng      = np_rng,\n    data_path   = os.path.join(config.dataset, \"dataset.npz\"),\n    batch_size  = config.batch_size)\n</code></pre> <pre>\n<code>Saving config file to experiments/X33_demo_harmonic/X33_demo_harmonic_METADATA.pkl\nDataset size: (400000, 12), kappa: 0.0393404\nVol[g]: 0.0277778, Vol[\u03a9]: 0.7060880\n</code>\n</pre> <pre><code>from cymyc.approx import models\n\nmetric_model_class = models.LearnedVector_spectral_nn_CICY\nmetric_model = metric_model_class(config.n_ambient_coords, config.ambient, config.n_units)\n\nseed = int(time.time()) # 42\nrng = random.PRNGKey(seed)\nrng, init_rng = random.split(rng)\n\n_params, init_rng = utils.random_params(init_rng, metric_model, data_dim=config.n_ambient_coords * 2)\nmetric_params = utils.load_params(_params, config.metric_checkpoint)  # parameters for trained metric NN\n</code></pre> <pre>\n<code>Compiling LearnedVector_spectral_nn.spectral_layer.\n</code>\n</pre> <pre><code>from flax import linen as nn\nfrom functools import partial\n\nfrom cymyc.approx import harmonic, eta_train\n</code></pre> <pre><code># initialize model\neta_model_class = models.CoeffNetwork_spectral_nn_CICY\neta_model = eta_model_class(\n    dim         = config.n_ambient_coords,\n    ambient     = config.ambient,\n    n_units     = config.n_units_harmonic,\n    activation  = nn.gelu)\n\nt0 = time.time()\nrng, init_rng = random.split(rng)\nlogger = utils.logger_setup('X33_demo_harmonic', filepath=os.path.abspath(''))\nlogger.info(eta_model.tabulate(init_rng, jnp.ones([1, config.n_ambient_coords * 2])))\n</code></pre> <pre>\n<code>14:30:40 INFO - logger_setup: /home/jt796/github/cymyc/docs/examples\n14:30:40 INFO - &lt;module&gt;: \n                     CoeffNetwork_spectral_nn_CICY Summary                      \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 path          \u2503 module        \u2503 inputs        \u2503 outputs       \u2503 params       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502               \u2502 CoeffNetwork\u2026 \u2502 float32[1,12] \u2502 -             \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502 complex64[1,\u2026 \u2502              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_0      \u2502 Dense         \u2502 float32[36]   \u2502 float32[64]   \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64]  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 kernel:      \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[36,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 2,368 (9.5   \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 KB)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_1      \u2502 Dense         \u2502 float32[64]   \u2502 float32[64]   \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64]  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 kernel:      \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 4,160 (16.6  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 KB)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_2      \u2502 Dense         \u2502 float32[64]   \u2502 float32[128]  \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[128] \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 kernel:      \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 8,320 (33.3  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 KB)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_3      \u2502 Dense         \u2502 float32[128]  \u2502 float32[64]   \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64]  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 kernel:      \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[128\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 8,256 (33.0  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 KB)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_4      \u2502 Dense         \u2502 float32[64]   \u2502 float32[42]   \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[42]  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 kernel:      \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[64,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 2,730 (10.9  \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 KB)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_coeffs \u2502 EinsumComplex \u2502 float32[42]   \u2502 complex64[1,\u2026 \u2502 bias:        \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[1,1\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 im_kernel:   \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[42,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 re_kernel:   \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 float32[42,\u2026 \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502              \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 26,775       \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 (107.1 KB)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502               \u2502               \u2502               \u2502         Total \u2502 52,609       \u2502\n\u2502               \u2502               \u2502               \u2502               \u2502 (210.4 KB)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                \n                      Total Parameters: 52,609 (210.4 KB)                       \n\n\n</code>\n</pre> <pre>\n<code>Compiling LearnedVector_spectral_nn.spectral_layer.\nCoeffNetwork_spectral_nn_CICY.__call__, coeff shape, (1, 15, 21)\n</code>\n</pre> <p>For the particular manifold we consider, there is one unique harmonic one-form, as \\(h^{(2,1)} = 1\\). Topological considerations mean the number of harmonic one-forms is equal to the number of independent ways we can deform the defining polynomials while remaining on the zero locus. From the definition of the manifold as the intersection of zero loci in \\(\\mathbb{P}^5\\), there is only one way to do this,</p> \\[ B_{\\psi} = \\left\\{\\begin{array}{c}Z_0^3 + Z_1^3 + Z_2^3 - 3 \\psi Z_3 Z_4 Z_5 = 0\\\\ Z_3^3 + Z_4^3 + Z_5^3 - 3 \\psi Z_0 Z_1 Z_2 = 0\\end{array} \\, : \\, \\psi \\in \\mathbb{C}\\right\\} \\subset \\mathbb{P}^5~. \\] <p>The single complex structure moduli direction corresponds to the trilinear polynomial deformations above, and we can write down this deformation explicitly. We also need to calculate some complex structure data associated with the manifold.</p> <p>There's too much information to comfortably carry around as arguments to functions used in optimisation. To remedy this, we wrap everything up into an appropriately filtered class - <code>harmonic_wp</code>, whose methods are compatible with <code>Jax</code> transformations.</p> <pre><code>from cymyc import alg_geo\nfrom examples import poly_spec\n\ndef X33_deformation(p, precision=np.complex128):\n    d1 = jnp.einsum(\"...a,aj-&amp;gt;...j\", jnp.expand_dims(p[3]*p[4]*p[5], axis=-1),\n                      jnp.asarray([[-3.,0.]], precision))\n    d2 = jnp.einsum(\"...a,aj-&amp;gt;...j\", jnp.expand_dims(p[0]*p[1]*p[2], axis=-1),\n                      jnp.asarray([[0.,-3.]], precision))\n    return d1 + d2\n\ndef _X33_coefficients(psi):\n    coefficients = [jnp.append(jnp.ones(3), -3.0*psi), jnp.append(jnp.ones(3), -3.0*psi)]\n    return coefficients\n\nmonomials, cy_dim, kmoduli, ambient = poly_spec.X33_spec()\ncoefficients = _X33_coefficients(psi)\n\ndQdz_info = [alg_geo.dQdz_poly(config.n_ambient_coords, m, c) for (m,c) in zip(monomials, coefficients)]\ndQdz_monomials, dQdz_coeffs = list(zip(*dQdz_info))\nconfig.dQdz_monomials = dQdz_monomials\nconfig.dQdz_coeffs = dQdz_coeffs\n</code></pre> <pre><code>g_FS_fn, g_correction_fn, pb_fn = models.helper_fns(config)\n# full transformation-compatible closure\nmetric_fn = jax.tree_util.Partial(models.ddbar_phi_model, params=metric_params, \n                                  g_ref_fn=g_FS_fn, g_correction_fn=g_correction_fn)\nharmonic_wp = harmonic.HarmonicFull(cy_dim, monomials, ambient, [X33_deformation], dQdz_monomials,\n                                dQdz_coeffs, metric_fn, pb_fn, _X33_coefficients, psi)\n</code></pre> <pre><code>import time, logging\nimport optax\n\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\noptimizer = optax.chain(\n        optax.clip_by_global_norm(1.0),\n        optax.adamw(config.learning_rate))\nparams, opt_state, init_rng = eta_train.create_train_state(init_rng, eta_model, optimizer, data_dim=config.n_ambient_coords * 2)\n\nstorage = defaultdict(list)\n\ntry:\n    device = jax.devices('gpu')[0]\nexcept:\n    device = jax.devices('cpu')[0]\n</code></pre> <pre>\n<code>Compiling LearnedVector_spectral_nn.spectral_layer.\nCoeffNetwork_spectral_nn_CICY.__call__, coeff shape, (1, 15, 21)\n</code>\n</pre> <pre><code>with jax.default_device(device):\n    logger.info(f\"Running on {device}\")\n\n    for epoch in range(config.n_epochs):\n        val_loader, val_data = dataloading.get_validation_data(val_loader, config.batch_size, data_val, np_rng)\n        storage = eta_train.callback(harmonic_wp.loss_breakdown, epoch, t0, 0, val_data, params, config, storage, logger, mode='VAL')\n\n        if epoch &amp;gt; 0:\n            train_loader = dataloading.data_loader(data_train, config.batch_size, np_rng)\n\n        train_loader_it = tqdm(train_loader, desc=f\"Epoch: {epoch}\", total=data_train[0].shape[0]//config.batch_size,\n                               colour='green', mininterval=0.1)\n        for t, data in enumerate(train_loader_it):\n            params, opt_state, loss = eta_train.train_step(data, params, opt_state, harmonic_wp.objective_function, optimizer)\n            train_loader_it.set_postfix_str(f\"loss: {loss:.5f}\", refresh=False)\n\nutils.basic_ckpt(params, opt_state, config.name, 'FIN')\nutils.save_logs(storage, config.name, 'FIN')\n</code></pre> <pre>\n<code>14:30:49 INFO - &lt;module&gt;: Running on cuda:0\n</code>\n</pre> <pre>\n<code>Compiling ddbar_phi_model\nCompiling phi_head\nCompiling LearnedVector_spectral_nn.spectral_layer.\nCompiling HarmonicFull.objective_function\nCompiling HarmonicFull.del_bar_zeta_complete\n</code>\n</pre> <pre>\n<code>/tmp/ipykernel_900602/1695235459.py:6: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[-3.,0.]], precision))\n/tmp/ipykernel_900602/1695235459.py:8: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[0.,-3.]], precision))\n</code>\n</pre> <pre>\n<code>Compiling coeff_head\n['layers_0', 'layers_1', 'layers_2', 'layers_3', 'layers_4', 'layers_coeffs']\nCompiling LearnedVector_spectral_nn.spectral_layer.\nCoeffNetwork_spectral_nn_CICY.__call__, coeff shape, (1, 15, 21)\n</code>\n</pre> <pre>\n<code>/tmp/ipykernel_900602/1695235459.py:6: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[-3.,0.]], precision))\n/tmp/ipykernel_900602/1695235459.py:8: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[0.,-3.]], precision))\n</code>\n</pre> <pre>\n<code>HarmonicFull.objective_function, codiff shape (1024, 1, 3)\nCompiling HarmonicFull.harmonic_rep_breakdown (1, 3, 6) (1, 5, 6) (1, 3, 3)\n</code>\n</pre> <pre>\n<code>/home/jt796/github/cymyc/cymyc/fubini_study.py:136: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in zeros is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  g_FS = jnp.zeros((n_coords, n_coords), dtype=cdtype)\n/home/jt796/github/cymyc/cymyc/fubini_study.py:75: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in eye is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  delta_mn = jnp.eye(complex_dim, dtype=cdtype)\n/home/jt796/dev/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:68: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in astype is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  return lax_numpy.astype(arr, dtype, copy=copy, device=device)\n/tmp/ipykernel_900602/1695235459.py:6: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[-3.,0.]], precision))\n/tmp/ipykernel_900602/1695235459.py:8: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[0.,-3.]], precision))\n</code>\n</pre> <pre>\n<code>Compiling HarmonicFull.zeta_jacobian_complete\nHarmonicFull.loss_breakdown: (1024, 1, 3, 3), (1024, 1, 3, 3), (1024, 1, 3, 3)\nHarmonicFull.loss_breakdown: (1, 1), (1, 1)\nHarmonicFull.loss_breakdown: (1, 1), (1, 1)\nHarmonic.section_network_transformed, basis_form shape (6, 6, 3)\nHarmonic.section_network_transformed, O2 shape (6, 6)\nHarmonicFull.transition_loss: (4, 1, 3), (4, 1, 3)\nHarmonicFull.transition_loss: (4, 3, 3)\nHarmonicFull.transition_loss: (4, 1)\n</code>\n</pre> <pre>\n<code>14:31:15 INFO - callback: [35.0s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62671+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.00045-0.00000j | G_WP_CY: 0.62649+0.00000j | G_WP_KS: 0.58940-0.00000j | G_WP_bundle: 0.62025-0.00000j | codiff_mean: 2.27620 | cup_product: 0.62649+0.00000j | loss: 1.65997 | polarisation: 0.01561 | ratio (cy/bundle): 1.01005+0.00000j | symmetry: 0.00149 | transition_loss: 0.00002 | \u03c3_measure: 0.01715\nEpoch: 0:   0%|                                                                                                                                                                                                                                       | 0/390 [00:00&lt;?, ?it/s]</code>\n</pre> <pre>\n<code>Compiling train_step\nCompiling HarmonicFull.objective_function\nHarmonicFull.objective_function, codiff shape (1024, 1, 3)\n</code>\n</pre> <pre>\n<code>Epoch: 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:32&lt;00:00, 11.99it/s, loss: 1.32860]\n14:31:47 INFO - callback: [67.6s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62566-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02046-0.00000j | G_WP_CY: 0.60843-0.00000j | G_WP_KS: 0.58757-0.00000j | G_WP_bundle: 0.60056-0.00000j | codiff_mean: 1.77433 | cup_product: 0.60843-0.00000j | loss: 1.32885 | polarisation: 0.01100 | ratio (cy/bundle): 1.01310+0.00000j | symmetry: 0.00105 | transition_loss: 0.00005 | \u03c3_measure: 0.01861\nEpoch: 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.61it/s, loss: 1.33671]\n14:32:02 INFO - callback: [82.3s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63023-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02211+0.00000j | G_WP_CY: 0.60896-0.00000j | G_WP_KS: 0.59290-0.00000j | G_WP_bundle: 0.59967-0.00000j | codiff_mean: 1.70031 | cup_product: 0.60896-0.00000j | loss: 1.27186 | polarisation: 0.00991 | ratio (cy/bundle): 1.01550+0.00000j | symmetry: 0.00094 | transition_loss: 0.00005 | \u03c3_measure: 0.01998\nEpoch: 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.55it/s, loss: 1.27861]\n14:32:17 INFO - callback: [97.0s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.64637-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02328-0.00000j | G_WP_CY: 0.61311+0.00000j | G_WP_KS: 0.60882-0.00000j | G_WP_bundle: 0.60562+0.00000j | codiff_mean: 1.63999 | cup_product: 0.61311+0.00000j | loss: 1.22227 | polarisation: 0.00982 | ratio (cy/bundle): 1.01236-0.00000j | symmetry: 0.00095 | transition_loss: 0.00005 | \u03c3_measure: 0.01776\nEpoch: 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.41it/s, loss: 1.16261]\n14:32:32 INFO - callback: [111.8s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.64294-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02476-0.00000j | G_WP_CY: 0.61118+0.00000j | G_WP_KS: 0.60449-0.00000j | G_WP_bundle: 0.60440-0.00000j | codiff_mean: 1.65331 | cup_product: 0.61118+0.00000j | loss: 1.23758 | polarisation: 0.01364 | ratio (cy/bundle): 1.01122+0.00000j | symmetry: 0.00132 | transition_loss: 0.00005 | \u03c3_measure: 0.01849\nEpoch: 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.39it/s, loss: 1.13474]\n14:32:46 INFO - callback: [126.6s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63438+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02462+0.00000j | G_WP_CY: 0.60475-0.00000j | G_WP_KS: 0.60065-0.00000j | G_WP_bundle: 0.59778-0.00000j | codiff_mean: 1.51980 | cup_product: 0.60475-0.00000j | loss: 1.13862 | polarisation: 0.01556 | ratio (cy/bundle): 1.01166+0.00000j | symmetry: 0.00148 | transition_loss: 0.00005 | \u03c3_measure: 0.01814\nEpoch: 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.40it/s, loss: 1.11696]\n14:33:01 INFO - callback: [141.4s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63007+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02768+0.00000j | G_WP_CY: 0.59541+0.00000j | G_WP_KS: 0.59187+0.00000j | G_WP_bundle: 0.59020+0.00000j | codiff_mean: 1.50262 | cup_product: 0.59541+0.00000j | loss: 1.12339 | polarisation: 0.01581 | ratio (cy/bundle): 1.00882-0.00000j | symmetry: 0.00151 | transition_loss: 0.00005 | \u03c3_measure: 0.01806\nEpoch: 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.32it/s, loss: 1.16596]\n14:33:16 INFO - callback: [156.2s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63916-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02702-0.00000j | G_WP_CY: 0.60619-0.00000j | G_WP_KS: 0.60372-0.00000j | G_WP_bundle: 0.59950-0.00000j | codiff_mean: 1.48826 | cup_product: 0.60619-0.00000j | loss: 1.11567 | polarisation: 0.01515 | ratio (cy/bundle): 1.01116+0.00000j | symmetry: 0.00145 | transition_loss: 0.00005 | \u03c3_measure: 0.01789\nEpoch: 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.25it/s, loss: 1.07817]\n14:33:31 INFO - callback: [171.1s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62881+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02891-0.00000j | G_WP_CY: 0.59561-0.00000j | G_WP_KS: 0.59570-0.00000j | G_WP_bundle: 0.59026-0.00000j | codiff_mean: 1.39257 | cup_product: 0.59561-0.00000j | loss: 1.04637 | polarisation: 0.01338 | ratio (cy/bundle): 1.00907+0.00000j | symmetry: 0.00131 | transition_loss: 0.00006 | \u03c3_measure: 0.01760\nEpoch: 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.29it/s, loss: 1.04522]\n14:33:46 INFO - callback: [186.0s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63322-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02955-0.00000j | G_WP_CY: 0.60660+0.00000j | G_WP_KS: 0.59505+0.00000j | G_WP_bundle: 0.59911+0.00000j | codiff_mean: 1.41148 | cup_product: 0.60660+0.00000j | loss: 1.07220 | polarisation: 0.01218 | ratio (cy/bundle): 1.01251-0.00000j | symmetry: 0.00117 | transition_loss: 0.00005 | \u03c3_measure: 0.01906\nEpoch: 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.33it/s, loss: 1.05662]\n14:34:01 INFO - callback: [200.8s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62742-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02984-0.00000j | G_WP_CY: 0.60118+0.00000j | G_WP_KS: 0.59164-0.00000j | G_WP_bundle: 0.59447-0.00000j | codiff_mean: 1.40329 | cup_product: 0.60118+0.00000j | loss: 1.06624 | polarisation: 0.01098 | ratio (cy/bundle): 1.01128+0.00000j | symmetry: 0.00106 | transition_loss: 0.00006 | \u03c3_measure: 0.01830\nEpoch: 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.30it/s, loss: 1.06050]\n14:34:16 INFO - callback: [215.7s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63662-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03060+0.00000j | G_WP_CY: 0.61175+0.00000j | G_WP_KS: 0.59872-0.00000j | G_WP_bundle: 0.60362+0.00000j | codiff_mean: 1.42114 | cup_product: 0.61175+0.00000j | loss: 1.08489 | polarisation: 0.01045 | ratio (cy/bundle): 1.01347-0.00000j | symmetry: 0.00101 | transition_loss: 0.00005 | \u03c3_measure: 0.01845\nEpoch: 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.32it/s, loss: 1.07115]\n14:34:30 INFO - callback: [230.6s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62945+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03060-0.00000j | G_WP_CY: 0.59642+0.00000j | G_WP_KS: 0.59091+0.00000j | G_WP_bundle: 0.58964-0.00000j | codiff_mean: 1.37652 | cup_product: 0.59642+0.00000j | loss: 1.04193 | polarisation: 0.00997 | ratio (cy/bundle): 1.01151+0.00000j | symmetry: 0.00096 | transition_loss: 0.00005 | \u03c3_measure: 0.01769\nEpoch: 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.31it/s, loss: 1.03597]\n14:34:45 INFO - callback: [245.4s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62905-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03046+0.00000j | G_WP_CY: 0.60431-0.00000j | G_WP_KS: 0.59016-0.00000j | G_WP_bundle: 0.59812-0.00000j | codiff_mean: 1.39410 | cup_product: 0.60431-0.00000j | loss: 1.06245 | polarisation: 0.00959 | ratio (cy/bundle): 1.01036+0.00000j | symmetry: 0.00093 | transition_loss: 0.00005 | \u03c3_measure: 0.01745\nEpoch: 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.31it/s, loss: 1.03161]\n14:35:00 INFO - callback: [260.3s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.64733-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02906+0.00000j | G_WP_CY: 0.61880-0.00000j | G_WP_KS: 0.61145+0.00000j | G_WP_bundle: 0.61192+0.00000j | codiff_mean: 1.35653 | cup_product: 0.61880-0.00000j | loss: 1.03833 | polarisation: 0.00947 | ratio (cy/bundle): 1.01123-0.00000j | symmetry: 0.00092 | transition_loss: 0.00005 | \u03c3_measure: 0.01875\nEpoch: 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.29it/s, loss: 1.02154]\n14:35:15 INFO - callback: [275.1s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62227-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03119+0.00000j | G_WP_CY: 0.59337+0.00000j | G_WP_KS: 0.58216+0.00000j | G_WP_bundle: 0.58690-0.00000j | codiff_mean: 1.35817 | cup_product: 0.59337+0.00000j | loss: 1.03111 | polarisation: 0.00933 | ratio (cy/bundle): 1.01102+0.00000j | symmetry: 0.00090 | transition_loss: 0.00006 | \u03c3_measure: 0.01775\nEpoch: 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.28it/s, loss: 1.00940]\n14:35:30 INFO - callback: [290.0s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63946-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03053+0.00000j | G_WP_CY: 0.61106+0.00000j | G_WP_KS: 0.60210-0.00000j | G_WP_bundle: 0.60366+0.00000j | codiff_mean: 1.36192 | cup_product: 0.61106+0.00000j | loss: 1.04222 | polarisation: 0.00969 | ratio (cy/bundle): 1.01226-0.00000j | symmetry: 0.00093 | transition_loss: 0.00006 | \u03c3_measure: 0.01847\nEpoch: 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.29it/s, loss: 1.04527]\n14:35:45 INFO - callback: [304.9s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.63897+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02938+0.00000j | G_WP_CY: 0.60864+0.00000j | G_WP_KS: 0.59739+0.00000j | G_WP_bundle: 0.60115+0.00000j | codiff_mean: 1.34631 | cup_product: 0.60864+0.00000j | loss: 1.03394 | polarisation: 0.00955 | ratio (cy/bundle): 1.01246-0.00000j | symmetry: 0.00092 | transition_loss: 0.00005 | \u03c3_measure: 0.01851\nEpoch: 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.31it/s, loss: 0.99576]\n14:36:00 INFO - callback: [319.7s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.64299+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03033+0.00000j | G_WP_CY: 0.61084-0.00000j | G_WP_KS: 0.60372-0.00000j | G_WP_bundle: 0.60402-0.00000j | codiff_mean: 1.31469 | cup_product: 0.61084-0.00000j | loss: 1.01105 | polarisation: 0.00958 | ratio (cy/bundle): 1.01129+0.00001j | symmetry: 0.00093 | transition_loss: 0.00005 | \u03c3_measure: 0.01810\nEpoch: 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.29it/s, loss: 1.02552]\n14:36:14 INFO - callback: [334.6s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.65684-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02964+0.00000j | G_WP_CY: 0.62522+0.00000j | G_WP_KS: 0.62042-0.00000j | G_WP_bundle: 0.61759+0.00000j | codiff_mean: 1.32823 | cup_product: 0.62522+0.00000j | loss: 1.03414 | polarisation: 0.00955 | ratio (cy/bundle): 1.01235-0.00000j | symmetry: 0.00092 | transition_loss: 0.00005 | \u03c3_measure: 0.01852\nEpoch: 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.25it/s, loss: 0.94967]\n14:36:29 INFO - callback: [349.5s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.65011+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.03001-0.00000j | G_WP_CY: 0.61602-0.00000j | G_WP_KS: 0.61144+0.00000j | G_WP_bundle: 0.60789-0.00000j | codiff_mean: 1.29495 | cup_product: 0.61602-0.00000j | loss: 1.00682 | polarisation: 0.00964 | ratio (cy/bundle): 1.01336+0.00000j | symmetry: 0.00093 | transition_loss: 0.00005 | \u03c3_measure: 0.01868\nEpoch: 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.21it/s, loss: 0.99232]\n14:36:44 INFO - callback: [364.4s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.62450-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02969+0.00000j | G_WP_CY: 0.59524-0.00000j | G_WP_KS: 0.58997-0.00000j | G_WP_bundle: 0.58911-0.00000j | codiff_mean: 1.27056 | cup_product: 0.59524-0.00000j | loss: 0.97583 | polarisation: 0.00978 | ratio (cy/bundle): 1.01040+0.00000j | symmetry: 0.00094 | transition_loss: 0.00005 | \u03c3_measure: 0.01735\nEpoch: 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.28it/s, loss: 1.00253]\n14:36:59 INFO - callback: [379.3s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.65316+0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02926-0.00000j | G_WP_CY: 0.62194+0.00000j | G_WP_KS: 0.61513-0.00000j | G_WP_bundle: 0.61363+0.00000j | codiff_mean: 1.27800 | cup_product: 0.62194+0.00000j | loss: 0.99417 | polarisation: 0.00985 | ratio (cy/bundle): 1.01354-0.00000j | symmetry: 0.00095 | transition_loss: 0.00005 | \u03c3_measure: 0.01898\nEpoch: 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.26it/s, loss: 0.97764]\n14:37:14 INFO - callback: [394.2s]: [VAL] | Iter: 0 | (\u03be,\u03be) (WP): 0.66280-0.00000j | (\u2202-bar \u03b8, \u2202-bar \u03b8) (WP): 0.02955-0.00000j | G_WP_CY: 0.63757-0.00000j | G_WP_KS: 0.62257-0.00000j | G_WP_bundle: 0.62755-0.00000j | codiff_mean: 1.32277 | cup_product: 0.63757-0.00000j | loss: 1.03961 | polarisation: 0.00977 | ratio (cy/bundle): 1.01598+0.00000j | symmetry: 0.00094 | transition_loss: 0.00005 | \u03c3_measure: 0.02021\nEpoch: 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:14&lt;00:00, 26.27it/s, loss: 1.00871]\n</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nplt.rcParams.update({'font.size': 14})\n\n# remove if no local tex installation\nplt.rcParams['text.usetex'] = True \nplt.rcParams['text.latex.preamble'] = r'\\usepackage[cm]{sfmath} \\usepackage{amssymb} \\usepackage{mathrsfs} \\usepackage{amsmath}'\nplt.rcParams['font.sans-serif'] = 'cm'\n</code></pre> <pre><code>fig = plt.figure(figsize=(17,7))\ngs=GridSpec(1,2)\nax1=fig.add_subplot(gs[0,0])\nax2=fig.add_subplot(gs[0,1])\n\nS = np.abs(storage['codiff_mean'])\nn = 32\nax1.plot(np.arange(len(S))[:n], np.abs(S)[:n], c='royalblue')\nax1.set_xlabel(f'Epochs')\nax1.set_ylabel(r'$\\int_X d\\mu_{\\Omega} \\, \\Delta_g \\tilde{\\eta}$')\nax1.grid(True, 'both')\n# ax1.set_yscale('log')\n\nR = storage['polarisation']\nax2.plot(np.arange(len(R))[:n], np.abs(R)[:n], c='royalblue')\nax2.set_xlabel(f'Epochs')\nax2.set_ylabel(r'Polarisation violation')\nax2.grid(True, 'both')\n# ax2.set_yscale('log')\n</code></pre> <pre><code>val_data_batched, psi = dataloading._batch_aux(\n    \"data/X33_demo/dataset.npz\", 1024, 'x_val',\n    metadata_key='psi', aux_keys=('y_val',), precision = np.float32)\n</code></pre> <pre>\n<code>Dataset size: (200000, 12), meta: 0.5000000\n</code>\n</pre> <pre><code># clunky but gets the job done\ndef normalised_cubic_yukawas_batched(harmonic_wp, params, data_loader):\n    from cymyc.utils import math_utils\n\n    wp, kappa = 0., 0.\n    vol_Omega, int_a, int_aa_p_bb = 0., 0., 0.\n    dQdz_monomials, dQdz_coeffs = harmonic_wp.dQdz_monomials, harmonic_wp.dQdz_coeffs\n    metric_fn, deformation_fn, pb_fn = harmonic_wp.metric_fn, harmonic_wp.deformation, harmonic_wp.pb_fn\n    n = 0\n    for _data in tqdm(zip(*data_loader), total=len(data_loader[0])):\n        p, aux = _data\n        p_c = math_utils.to_complex(p)\n        weights, dVol_Omega = aux[:,0], aux[:,1]\n        pullbacks = jax.vmap(pb_fn)(math_utils.to_complex(p))\n        B = p.shape[0]\n        _data = (p, weights, dVol_Omega)\n\n        _vol_Omega, _int_a, _int_aa_p_bb = harmonic_wp._compute_wp_metric_diagonal_batch_i(\n                                                p_c, weights, pullbacks, dQdz_monomials,\n                                                dQdz_coeffs, deformation_fn)\n\n        vol_Omega = math_utils.online_update(vol_Omega, _vol_Omega, n, B)\n        int_a = math_utils.online_update(int_a, _int_a, n, B)\n        int_aa_p_bb = math_utils.online_update(int_aa_p_bb, _int_aa_p_bb, n, B)\n\n        # Trilinear coupling\n        _kappa = harmonic_wp.yukawas(\n            p_c, dQdz_monomials, dQdz_coeffs, deformation_fn, deformation_fn,\n            deformation_fn, weights, pullbacks)\n        kappa = math_utils.online_update(kappa, _kappa, n, B)\n\n        _g_pred = jax.vmap(metric_fn)(p)\n        _eta, *_ = jax.vmap(harmonic_wp.harmonic_rep_breakdown, in_axes=(0,None))(p, params)\n        _wp = harmonic_wp.inner_product_Hodge(_data, _eta, _g_pred)\n        wp = math_utils.online_update(wp, _wp, n, B)\n        n += B\n\n    yuk_normalised = jnp.abs(kappa) / (vol_Omega) * wp**(-3/2)\n    g_wp_KS = -int_aa_p_bb / vol_Omega + (jnp.conjugate(int_a) * int_a) / vol_Omega**2\n\n    return {\n        \"yuk_normalised\":   yuk_normalised,\n        \"kappa\":            kappa,\n        \"wp\":               wp,\n        \"vol_Omega\":        vol_Omega,\n        \"wp_KS\":            g_wp_KS}\n</code></pre> <pre><code>yukawa_data = normalised_cubic_yukawas_batched(harmonic_wp, params, val_data_batched)\nyukawa_data\n</code></pre> <pre>\n<code>  0%|                                                                                                                                                                                                                                                 | 0/195 [00:00&lt;?, ?it/s]/tmp/ipykernel_900602/1695235459.py:6: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[-3.,0.]], precision))\n/tmp/ipykernel_900602/1695235459.py:8: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[0.,-3.]], precision))\n</code>\n</pre> <pre>\n<code>Compiling ddbar_phi_model\nCompiling phi_head\nCompiling LearnedVector_spectral_nn.spectral_layer.\nCompiling HarmonicFull.del_bar_zeta_complete\nCompiling coeff_head\n['layers_0', 'layers_1', 'layers_2', 'layers_3', 'layers_4', 'layers_coeffs']\nCompiling LearnedVector_spectral_nn.spectral_layer.\nCoeffNetwork_spectral_nn_CICY.__call__, coeff shape, (1, 15, 21)\n</code>\n</pre> <pre>\n<code>/tmp/ipykernel_900602/1695235459.py:6: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[-3.,0.]], precision))\n/tmp/ipykernel_900602/1695235459.py:8: UserWarning: Explicitly requested dtype &lt;class 'numpy.complex128'&gt; requested in asarray is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n  jnp.asarray([[0.,-3.]], precision))\n</code>\n</pre> <pre>\n<code>Compiling HarmonicFull.harmonic_rep_breakdown (1, 3, 6) (1, 5, 6) (1, 3, 3)\n</code>\n</pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 195/195 [00:21&lt;00:00,  9.18it/s]\n</code>\n</pre> <pre>\n<code>{'yuk_normalised': Array([[1.0534348+2.6020035e-07j]], dtype=complex64),\n 'kappa': Array(-0.3489358+0.00036438j, dtype=complex64),\n 'wp': Array([[0.60370165-9.94103e-08j]], dtype=complex64),\n 'vol_Omega': Array(0.7061624, dtype=float32),\n 'wp_KS': Array(0.6035413+7.4317977e-13j, dtype=complex64)}</code>\n</pre> <pre><code>yukawa_data = jax.tree_util.tree_map(lambda x: x.item(), yukawa_data)\n</code></pre> <pre><code>print(f\"Normalized Yukawa coupling \u03bb @ (\u03c8={psi}) = {yukawa_data['yuk_normalised']:.07f}\")\nprint(f\"Harmonic calculation: WP @ (\u03c8={psi}) = {yukawa_data['wp']:.07f}\")\nprint(f\"Kodaira-Spencer calculation: WP @ (\u03c8={psi}) = {yukawa_data['wp_KS']:.07f}\")\nprint(f\"Relative error in Weil-Petersson metric = {np.abs((yukawa_data['wp'] - yukawa_data['wp_KS'])/yukawa_data['wp_KS'])*100:.04f}%\")\n</code></pre> <pre>\n<code>Normalized Yukawa coupling \u03bb @ (\u03c8=0.5) = 1.0534348+0.0000003j\nHarmonic calculation: WP @ (\u03c8=0.5) = 0.6037017-0.0000001j\nKodaira-Spencer calculation: WP @ (\u03c8=0.5) = 0.6035413+0.0000000j\nRelative error in Weil-Petersson metric = 0.0266%\n</code>\n</pre>"},{"location":"examples/harmonic/#approximation-of-laplacian-zero-modes","title":"Approximation of Laplacian zero modes","text":"<p>In this example notebook, the second in of a pair, we consider a complex manifold \\(X\\), and approximate the zero modes of the Laplacian \\(\\Delta_g\\) on \\(X\\) by optimisation of the natural associated variational problem. One may regard this as an example of how to use the approximate metric to study the geometry of \\(X\\).</p> <p>The manifold \\(X\\) is the same Calabi-Yau threefold defined in the previous example, where we found an approximation to the unique Ricci-flat metric tensor on \\(X\\). We will use the points sampled and optimsed parameters saved by the previous example.</p>"},{"location":"examples/harmonic/#motivation","title":"Motivation","text":"<p>This will be a brief overview with technical details smoothed over for the ease of exposition - for the full story, please consult this article. </p> <p>We are interested in differential forms on the Calabi-Yau, \\(\\eta \\in \\Omega^1(X)\\), which are annihilated by the Laplacian on \\(X\\), $$ \\Delta_g \\eta = 0~.$$</p> <p>Evaluation of the Laplacian requires the metric on \\(X\\) - which makes sense, as eigenmodes on manifolds should tell you about geometry! For physical reasons, in string compactification scenarios, we are interested in eigenmodes which are harmonic w.r.t. the Ricci-flat metric. These correspond to observable physical matter fields in string compactifications scenarios.</p> <p>With harmonic forms in hand, we may predict the masses and strengths with which these particles interact at low energies. The end goal is to predict if a given 'string model' (of which there are exceptionally many) recovers a quantum field theory with properties close to our universe at low energies.</p>"},{"location":"examples/harmonic/#load-data-and-metric-checkpoint","title":"Load data and metric checkpoint","text":"<p>We load the points sampled from \\(X\\) in the previous notebook, as well as the parameters for the approximate Ricci-flat metric.</p>"},{"location":"examples/harmonic/#harmonic-model-ansatz","title":"Harmonic model ansatz","text":"<p>Our variational ansatz \\(\\tilde{\\eta}_{\\lambda}\\) is obtained as an \\(\\overline{\\partial}\\)-exact correction from some easily computable reference form \\(\\phi \\in H^1(T_X)\\), and the natural variational objective to minimise is the Laplacian itself,</p> \\[\\tilde{\\eta}(\\cdot; \\lambda) = \\phi + \\bar{\\partial} \\mathfrak{s}(\\cdot; \\lambda), \\quad \\lambda = \\textsf{argmin}_{\\lambda' \\in \\Lambda} \\Delta_g \\tilde{\\eta}(\\cdot; \\lambda').\\] <p>Here \\(\\mathfrak{s}\\) is a section of the (holomorphic) tangent bundle over \\(X\\). The approximation problem thus reduces to finding a way to model a section of the tangent bundle \\(\\mathfrak{s} \\in \\Gamma(T_X)\\) using a parameterised function - this is far from obvious on a manifold with nontrivial topology! </p> <p>The core idea is to construct a basis of sections \\(\\{ \\mathbf{e}^i \\}_i\\) of \\(T_X\\), and to take \\(\\mathfrak{s}\\) to be a linear combination of the basis elements, with the coefficients parameterised by a vector-valued globally defined function \\(\\psi\\): $$ \\mathfrak{s} = \\sum_{\\mu} \\psi_{\\mu} \\mathbf{e}^{\\mu} ~.$$ We again we leave the full story to this article, but note this is crucial to ensure that \\(\\tilde{\\eta}\\) is a bona-fide geometrical object globally defined over \\(X\\) - one gets nonsensical answers if the ansatz does not respect the topology of \\(X\\).</p> <p>Note: The objective requires taking the third derivative of the neural network modelling the metric, so this example runs significantly faster on a GPU.</p>"},{"location":"examples/harmonic/#optimisation-loop-for-harmonic-zero-modes","title":"Optimisation loop for harmonic zero modes","text":"<p>This is again fairly standard - note Jax is more bare-metal than other libraries, so we write the looping logic ourselves. </p> <p><code>jit</code> compilation introduces a delay the first time the <code>train_step</code> function is called, but executes quickly when called subsequently. We pay an initial up-front cost for compilation of Python functions into a form efficiently executable by an accelerator, which will be repaid during the execution itself.</p>"},{"location":"examples/harmonic/#sanity-check","title":"Sanity check","text":"<p>We can plot the evolution of the Laplacian over the optimisation process to check if the resulting ansatz \\(\\tilde{\\eta}\\) is approaching something harmonic. Since the Laplacian is defined as $$\\Delta_g = \\frac{1}{2} \\left( dd^{\\dagger} + d^{\\dagger}d\\right)~, $$ we can study the norm of the codifferential, \\(\\left(d^{\\dagger} \\tilde{\\eta}, d^{\\dagger} \\tilde{\\eta}\\right)_g\\) to ensure \\(\\Delta_g \\tilde{\\eta} \\approx 0\\). </p> <p>We can also study the degree to which the polarisation-preserving condition is violated, which follows from harmonicity of \\(\\eta\\), and asserts \\(\\eta_{\\overline{\\alpha}\\overline{\\nu}} = g_{\\mu \\overline{\\nu}} \\eta^{\\mu}_{\\; \\overline{\\alpha}}\\).</p>"},{"location":"examples/harmonic/#yukawa-coupling-computation","title":"Yukawa coupling computation","text":"<p>For the particular class of string models we consider, we can calculate physical observables ('Yukawa couplings') via two ways:</p> <ul> <li>A computation from deformation theory, exact up to integration error.</li> <li>Using the approximate harmonic forms we have just optimised for.</li> </ul> <p>The purpose of this experiment is really a sanity check to ensure that our proposed method can generalise to other string models where there is no equivalent of deformation theory applicable, and the approximate harmonic forms are the only avenue for calculation of certain physical observables. We compare above methods below via an evaluation on the validation set.</p>"},{"location":"examples/metric_approx/","title":"Calabi-Yau metrics","text":"<pre><code>import jax\nfrom jax import random\nimport jax.numpy as jnp\n\nimport os, time\nimport numpy as np\n\nfrom cymyc.utils.pointgen_cicy import PointGenerator \n</code></pre> <pre><code># Choose value of moduli parameter psi\npsi = 0.5\n\nmonomials_1 = np.asarray([\n    [3, 0, 0, 0, 0, 0],\n    [0, 3, 0, 0, 0, 0],\n    [0, 0, 3, 0, 0, 0],\n    [0, 0, 0, 1, 1, 1]], dtype=np.int64)\n\nmonomials_2 = np.asarray([\n    [0, 0, 0, 3, 0, 0],\n    [0, 0, 0, 0, 3, 0],\n    [0, 0, 0, 0, 0, 3],\n    [1, 1, 1, 0, 0, 0]], dtype=np.int64)\n\nmonomials = [monomials_1, monomials_2]\n\ncy_dim = 3\nkmoduli = np.ones(1)\nambient = np.array([5])\ndim = 6\n\ncoeff_fn = lambda psi: [np.append(np.ones(3), -3.0*psi), np.append(np.ones(3), -3.0*psi)]\ncoefficients = coeff_fn(psi)\npoly_data = (monomials, cy_dim, kmoduli, ambient)\n</code></pre> <pre><code>seed = 42\nrng = random.PRNGKey(seed)\nrng, pg_rng, init_rng = random.split(rng, 3)\ndpath = \"data/X33_demo\"\n\nn_p = 400000  # Number of training points\nv_p = 200000  # Number of validation points\n\nimport warnings\nwarnings.filterwarnings('ignore')\n</code></pre> <pre><code>pg_cicy = PointGenerator(rng, cy_dim, monomials, ambient, coefficients, kmoduli)\ncicy_pts = pg_cicy.sample_intersect_cicy(init_rng, n_p + v_p)\npg_cicy.export(dpath, cicy_pts, n_p, v_p, psi, poly_data, coefficients)\n</code></pre> <pre>\n<code>Generating 600000 points ...\n</code>\n</pre> <pre>\n<code>[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   16.2s\n[Parallel(n_jobs=-1)]: Done 150752 tasks      | elapsed:  1.1min\n[Parallel(n_jobs=-1)]: Done 489872 tasks      | elapsed:  2.5min\n[Parallel(n_jobs=-1)]: Done 603010 out of 603010 | elapsed:  2.9min finished\n</code>\n</pre> <pre>\n<code>Max locus violation: 1.67721e-13\nUsing kmoduli, [1.]\n</code>\n</pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:04&lt;00:00,  2.97it/s]\n</code>\n</pre> <pre>\n<code>Volume 9*t_0**3\nVolume at chosen Kahler moduli 9.0\nkappa: 0.0393404\n</code>\n</pre> <pre><code>from cymyc import dataloading\nfrom cymyc.utils import gen_utils as utils\nfrom cymyc.approx.default_config import config\n\nclass args(object):\n    # specify training config. For more options, see `src/approx/default_config`\n    name = 'X33_demo'\n    learning_rate = 1e-4\n    n_epochs = 128  # change as necessary!\n    dataset = dpath\n    batch_size = 1024\n    n_units = [48,48,48,48]\n\n# Override default arguments from config file with provided command line arguments\nconfig = utils.override_default_args(args, config)\nconfig = utils.read_metadata(config)  # load dataset metadata\n\nnp_rng = np.random.default_rng()\ndata_train, data_val, train_loader, val_loader, psi = dataloading.initialize_loaders_train(\n    np_rng      = np_rng,\n    data_path   = os.path.join(config.dataset, \"dataset.npz\"),\n    batch_size  = config.batch_size)\n</code></pre> <pre>\n<code>Saving config file to experiments/X33_demo/X33_demo_METADATA.pkl\nDataset size: (400000, 12), kappa: 0.0393404\nVol[g]: 0.0277778, Vol[\u03a9]: 0.7060880\n</code>\n</pre> <pre><code>import optax\nfrom functools import partial\n\nfrom cymyc.approx import models\nfrom cymyc.approx.train import create_train_state, train_step, callback\n</code></pre> <pre><code>key, _key = jax.random.split(rng)\n\nmetric_model = models.LearnedVector_spectral_nn_CICY(\n    dim=dim, ambient=ambient, n_units=config.n_units)\n\ng_FS_fn, g_correction_fn, *_ = models.helper_fns(config)\n\noptimizer = optax.adamw(config.learning_rate)\nmetric_params, opt_state, init_rng = create_train_state(_key, metric_model, optimizer, data_dim=dim * 2)\n# partial closure\nmetric_fn = partial(models.ddbar_phi_model, g_ref_fn=g_FS_fn, g_correction_fn=g_correction_fn)\n\nt0 = time.time()\nlogger = utils.logger_setup('X33_demo', filepath=os.path.abspath(''))\nlogger.info(metric_model.tabulate(init_rng, jnp.ones([1, config.n_ambient_coords * 2])))\n</code></pre> <pre>\n<code>Compiling LearnedVector_spectral_nn.spectral_layer.\n</code>\n</pre> <pre>\n<code>14:25:26 INFO - logger_setup: /home/jt796/github/cymyc/docs/examples\n14:25:26 INFO - &lt;module&gt;: \n                     LearnedVector_spectral_nn_CICY Summary                     \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 path     \u2503 module           \u2503 inputs        \u2503 outputs     \u2503 params           \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502          \u2502 LearnedVector_s\u2026 \u2502 float64[1,12] \u2502 float64[]   \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_0 \u2502 Dense            \u2502 float64[36]   \u2502 float64[48] \u2502 bias:            \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48]      \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 kernel:          \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[36,48]   \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502                  \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 1,776 (7.1 KB)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_1 \u2502 Dense            \u2502 float64[48]   \u2502 float64[48] \u2502 bias:            \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48]      \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 kernel:          \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48,48]   \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502                  \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 2,352 (9.4 KB)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_2 \u2502 Dense            \u2502 float64[48]   \u2502 float64[48] \u2502 bias:            \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48]      \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 kernel:          \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48,48]   \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502                  \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 2,352 (9.4 KB)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 layers_3 \u2502 Dense            \u2502 float64[48]   \u2502 float64[48] \u2502 bias:            \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48]      \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 kernel:          \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48,48]   \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502                  \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 2,352 (9.4 KB)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 scalar   \u2502 Dense            \u2502 float64[48]   \u2502 float64[1]  \u2502 bias: float32[1] \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 kernel:          \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 float32[48,1]    \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502                  \u2502\n\u2502          \u2502                  \u2502               \u2502             \u2502 49 (196 B)       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          \u2502                  \u2502               \u2502       Total \u2502 8,881 (35.5 KB)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                \n                       Total Parameters: 8,881 (35.5 KB)                        \n\n\n</code>\n</pre> <pre>\n<code>Compiling LearnedVector_spectral_nn.spectral_layer.\n</code>\n</pre> <pre><code>import time\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\neval_interval = 5\nstorage = defaultdict(list)\n\ntry:\n    device = jax.devices('gpu')[0]\nexcept:\n    device = jax.devices('cpu')[0]\n\nwith jax.default_device(device):\n    logger.info(f\"Running on {device}\")\n\n    for epoch in range(config.n_epochs):\n        if (epoch % eval_interval == 0):\n            val_loader, val_data = dataloading.get_validation_data(val_loader, config.batch_size, data_val, np_rng)\n            storage = callback(epoch, t0, 0, val_data, metric_params, metric_fn, g_FS_fn, config, storage, logger, mode='VAL')\n\n        if epoch &amp;gt; 0:\n            train_loader = dataloading.data_loader(data_train, config.batch_size, np_rng)\n\n        train_loader_it = tqdm(train_loader, desc=f\"Epoch: {epoch}\", total=data_train[0].shape[0]//config.batch_size,\n                               colour='green', mininterval=0.1)\n        for t, data in enumerate(train_loader_it):\n            metric_params, opt_state, loss = train_step(data, metric_params, opt_state, metric_fn, optimizer, config.kappa)\n            train_loader_it.set_postfix_str(f\"loss: {loss:.5f}\", refresh=False)\n\n# save parameters to disk\nutils.basic_ckpt(metric_params, opt_state, config.name, 'FIN')\nutils.save_logs(storage, config.name, 'FIN')\n</code></pre> <pre>\n<code>14:25:26 INFO - &lt;module&gt;: Running on cuda:0\n</code>\n</pre> <pre>\n<code>Compiling ddbar_phi_model\nCompiling phi_head\nCompiling LearnedVector_spectral_nn.spectral_layer.\nCompiling ricci_measure\n</code>\n</pre> <pre>\n<code>14:26:18 INFO - callback: [51.7s]: [VAL] | Epoch: 0 | Iter: 0 | chi_form: -147.8624+0.0102j | det_g: 0.0018 | einstein_norm: 4.0715 | kahler_loss: 0.0000 | monge_ampere_loss: 0.2222 | ricci_measure: 0.1323 | ricci_scalar: -2.6378 | ricci_tensor_norm: 0.1802 | sigma_measure: 0.3148 | vol_CY: 0.0279 | vol_Omega: 0.7042 | vol_loss: 0.0001\nEpoch: 0:   0%|                                                                                                                                                                                                                                       | 0/390 [00:00&lt;?, ?it/s]</code>\n</pre> <pre>\n<code>Compiling ddbar_phi_model\n</code>\n</pre> <pre>\n<code>Epoch: 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:05&lt;00:00, 76.54it/s, loss: 0.09083]\nEpoch: 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 572.91it/s, loss: 0.06886]\nEpoch: 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 580.58it/s, loss: 0.04289]\nEpoch: 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 583.24it/s, loss: 0.02926]\nEpoch: 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 589.58it/s, loss: 0.02722]\n14:26:28 INFO - callback: [61.9s]: [VAL] | Epoch: 5 | Iter: 0 | chi_form: -149.3161-0.0202j | det_g: 0.0017 | einstein_norm: 1.2555 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0270 | ricci_measure: 0.0435 | ricci_scalar: -0.2172 | ricci_tensor_norm: 0.0606 | sigma_measure: 0.0381 | vol_CY: 0.0278 | vol_Omega: 0.7086 | vol_loss: 0.0000\nEpoch: 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 534.56it/s, loss: 0.02547]\nEpoch: 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 561.00it/s, loss: 0.02498]\nEpoch: 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 589.92it/s, loss: 0.02409]\nEpoch: 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 562.07it/s, loss: 0.02171]\nEpoch: 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 557.11it/s, loss: 0.02210]\n14:26:34 INFO - callback: [67.2s]: [VAL] | Epoch: 10 | Iter: 0 | chi_form: -146.9219+0.0199j | det_g: 0.0018 | einstein_norm: 1.1907 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0226 | ricci_measure: 0.0381 | ricci_scalar: 0.0463 | ricci_tensor_norm: 0.0576 | sigma_measure: 0.0321 | vol_CY: 0.0277 | vol_Omega: 0.7050 | vol_loss: 0.0000\nEpoch: 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 542.18it/s, loss: 0.02192]\nEpoch: 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 551.39it/s, loss: 0.02137]\nEpoch: 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 560.51it/s, loss: 0.01998]\nEpoch: 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 561.09it/s, loss: 0.02048]\nEpoch: 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 567.97it/s, loss: 0.01986]\n14:26:39 INFO - callback: [72.7s]: [VAL] | Epoch: 15 | Iter: 0 | chi_form: -143.9541+0.0050j | det_g: 0.0017 | einstein_norm: 1.1205 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0191 | ricci_measure: 0.0373 | ricci_scalar: 0.1093 | ricci_tensor_norm: 0.0530 | sigma_measure: 0.0270 | vol_CY: 0.0279 | vol_Omega: 0.7076 | vol_loss: 0.0001\nEpoch: 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 548.10it/s, loss: 0.01922]\nEpoch: 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 577.24it/s, loss: 0.01867]\nEpoch: 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 575.49it/s, loss: 0.01838]\nEpoch: 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 568.85it/s, loss: 0.01876]\nEpoch: 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 568.61it/s, loss: 0.01843]\n14:26:44 INFO - callback: [78.0s]: [VAL] | Epoch: 20 | Iter: 0 | chi_form: -145.8684+0.0103j | det_g: 0.0017 | einstein_norm: 1.0711 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0172 | ricci_measure: 0.0343 | ricci_scalar: -0.0931 | ricci_tensor_norm: 0.0502 | sigma_measure: 0.0245 | vol_CY: 0.0276 | vol_Omega: 0.7030 | vol_loss: 0.0001\nEpoch: 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 521.85it/s, loss: 0.01772]\nEpoch: 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 531.52it/s, loss: 0.01840]\nEpoch: 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 529.54it/s, loss: 0.01716]\nEpoch: 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.46it/s, loss: 0.01619]\nEpoch: 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 573.31it/s, loss: 0.01558]\n14:26:50 INFO - callback: [83.5s]: [VAL] | Epoch: 25 | Iter: 0 | chi_form: -141.6123-0.0002j | det_g: 0.0017 | einstein_norm: 1.1405 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0162 | ricci_measure: 0.0370 | ricci_scalar: -0.0062 | ricci_tensor_norm: 0.0506 | sigma_measure: 0.0229 | vol_CY: 0.0278 | vol_Omega: 0.7065 | vol_loss: 0.0000\nEpoch: 25: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 527.47it/s, loss: 0.01658]\nEpoch: 26: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 529.48it/s, loss: 0.01555]\nEpoch: 27: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 555.86it/s, loss: 0.01646]\nEpoch: 28: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 573.49it/s, loss: 0.01629]\nEpoch: 29: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 566.63it/s, loss: 0.01639]\n14:26:55 INFO - callback: [89.0s]: [VAL] | Epoch: 30 | Iter: 0 | chi_form: -136.6402-0.0538j | det_g: 0.0017 | einstein_norm: 1.0027 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0154 | ricci_measure: 0.0323 | ricci_scalar: 0.0722 | ricci_tensor_norm: 0.0476 | sigma_measure: 0.0218 | vol_CY: 0.0277 | vol_Omega: 0.7025 | vol_loss: 0.0001\nEpoch: 30: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 532.89it/s, loss: 0.01503]\nEpoch: 31: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 538.50it/s, loss: 0.01551]\nEpoch: 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 566.12it/s, loss: 0.01464]\nEpoch: 33: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 579.78it/s, loss: 0.01483]\nEpoch: 34: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 582.54it/s, loss: 0.01501]\n14:27:01 INFO - callback: [94.4s]: [VAL] | Epoch: 35 | Iter: 0 | chi_form: -153.3210+0.0054j | det_g: 0.0018 | einstein_norm: 1.1005 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0161 | ricci_measure: 0.0376 | ricci_scalar: -0.2312 | ricci_tensor_norm: 0.0474 | sigma_measure: 0.0227 | vol_CY: 0.0280 | vol_Omega: 0.7134 | vol_loss: 0.0002\nEpoch: 35: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 540.23it/s, loss: 0.01448]\nEpoch: 36: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 558.39it/s, loss: 0.01574]\nEpoch: 37: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 572.88it/s, loss: 0.01526]\nEpoch: 38: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 562.43it/s, loss: 0.01472]\nEpoch: 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 539.29it/s, loss: 0.01496]\n14:27:06 INFO - callback: [99.8s]: [VAL] | Epoch: 40 | Iter: 0 | chi_form: -146.8696-0.0111j | det_g: 0.0017 | einstein_norm: 1.0653 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0155 | ricci_measure: 0.0322 | ricci_scalar: 0.1571 | ricci_tensor_norm: 0.0465 | sigma_measure: 0.0218 | vol_CY: 0.0278 | vol_Omega: 0.7052 | vol_loss: 0.0000\nEpoch: 40: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 568.74it/s, loss: 0.01487]\nEpoch: 41: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 565.72it/s, loss: 0.01568]\nEpoch: 42: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 566.88it/s, loss: 0.01412]\nEpoch: 43: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 575.04it/s, loss: 0.01551]\nEpoch: 44: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 560.32it/s, loss: 0.01417]\n14:27:11 INFO - callback: [105.2s]: [VAL] | Epoch: 45 | Iter: 0 | chi_form: -153.1961+0.0116j | det_g: 0.0017 | einstein_norm: 1.0842 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0153 | ricci_measure: 0.0343 | ricci_scalar: -0.1280 | ricci_tensor_norm: 0.0449 | sigma_measure: 0.0218 | vol_CY: 0.0279 | vol_Omega: 0.7093 | vol_loss: 0.0001\nEpoch: 45: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 547.89it/s, loss: 0.01515]\nEpoch: 46: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 551.31it/s, loss: 0.01372]\nEpoch: 47: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 573.33it/s, loss: 0.01479]\nEpoch: 48: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 559.24it/s, loss: 0.01452]\nEpoch: 49: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 572.21it/s, loss: 0.01526]\n14:27:17 INFO - callback: [110.6s]: [VAL] | Epoch: 50 | Iter: 0 | chi_form: -132.6214+0.0156j | det_g: 0.0017 | einstein_norm: 0.9498 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0137 | ricci_measure: 0.0310 | ricci_scalar: 0.3576 | ricci_tensor_norm: 0.0425 | sigma_measure: 0.0192 | vol_CY: 0.0277 | vol_Omega: 0.7025 | vol_loss: 0.0001\nEpoch: 50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 564.28it/s, loss: 0.01403]\nEpoch: 51: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 558.20it/s, loss: 0.01402]\nEpoch: 52: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 569.94it/s, loss: 0.01399]\nEpoch: 53: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 562.36it/s, loss: 0.01385]\nEpoch: 54: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 562.99it/s, loss: 0.01393]\n14:27:22 INFO - callback: [115.9s]: [VAL] | Epoch: 55 | Iter: 0 | chi_form: -141.8868+0.0201j | det_g: 0.0017 | einstein_norm: 1.0203 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0144 | ricci_measure: 0.0272 | ricci_scalar: 0.1503 | ricci_tensor_norm: 0.0422 | sigma_measure: 0.0203 | vol_CY: 0.0278 | vol_Omega: 0.7064 | vol_loss: 0.0000\nEpoch: 55: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 572.05it/s, loss: 0.01462]\nEpoch: 56: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 584.43it/s, loss: 0.01446]\nEpoch: 57: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 567.86it/s, loss: 0.01493]\nEpoch: 58: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 565.89it/s, loss: 0.01497]\nEpoch: 59: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 563.96it/s, loss: 0.01303]\n14:27:28 INFO - callback: [121.2s]: [VAL] | Epoch: 60 | Iter: 0 | chi_form: -142.2032+0.0036j | det_g: 0.0017 | einstein_norm: 0.9002 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0140 | ricci_measure: 0.0273 | ricci_scalar: 0.0055 | ricci_tensor_norm: 0.0406 | sigma_measure: 0.0198 | vol_CY: 0.0278 | vol_Omega: 0.7060 | vol_loss: 0.0000\nEpoch: 60: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 550.94it/s, loss: 0.01336]\nEpoch: 61: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 547.94it/s, loss: 0.01393]\nEpoch: 62: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 545.21it/s, loss: 0.01484]\nEpoch: 63: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 548.59it/s, loss: 0.01385]\nEpoch: 64: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 544.52it/s, loss: 0.01368]\n14:27:33 INFO - callback: [126.7s]: [VAL] | Epoch: 65 | Iter: 0 | chi_form: -150.3081+0.0003j | det_g: 0.0017 | einstein_norm: 0.9176 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0136 | ricci_measure: 0.0289 | ricci_scalar: -0.1310 | ricci_tensor_norm: 0.0419 | sigma_measure: 0.0195 | vol_CY: 0.0277 | vol_Omega: 0.7054 | vol_loss: 0.0001\nEpoch: 65: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 562.41it/s, loss: 0.01326]\nEpoch: 66: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 556.48it/s, loss: 0.01411]\nEpoch: 67: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.83it/s, loss: 0.01347]\nEpoch: 68: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 549.33it/s, loss: 0.01386]\nEpoch: 69: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 559.46it/s, loss: 0.01356]\n14:27:38 INFO - callback: [132.1s]: [VAL] | Epoch: 70 | Iter: 0 | chi_form: -133.0434-0.0148j | det_g: 0.0018 | einstein_norm: 1.0014 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0133 | ricci_measure: 0.0276 | ricci_scalar: 0.2083 | ricci_tensor_norm: 0.0416 | sigma_measure: 0.0187 | vol_CY: 0.0278 | vol_Omega: 0.7047 | vol_loss: 0.0000\nEpoch: 70: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 544.78it/s, loss: 0.01418]\nEpoch: 71: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 557.75it/s, loss: 0.01356]\nEpoch: 72: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 567.88it/s, loss: 0.01371]\nEpoch: 73: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 556.92it/s, loss: 0.01426]\nEpoch: 74: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 557.79it/s, loss: 0.01390]\n14:27:44 INFO - callback: [137.5s]: [VAL] | Epoch: 75 | Iter: 0 | chi_form: -144.0889+0.0023j | det_g: 0.0018 | einstein_norm: 0.9646 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0145 | ricci_measure: 0.0259 | ricci_scalar: -0.0402 | ricci_tensor_norm: 0.0418 | sigma_measure: 0.0207 | vol_CY: 0.0277 | vol_Omega: 0.7032 | vol_loss: 0.0001\nEpoch: 75: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 545.42it/s, loss: 0.01353]\nEpoch: 76: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 567.56it/s, loss: 0.01373]\nEpoch: 77: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 563.65it/s, loss: 0.01263]\nEpoch: 78: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 583.76it/s, loss: 0.01417]\nEpoch: 79: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 577.58it/s, loss: 0.01379]\n14:27:49 INFO - callback: [142.8s]: [VAL] | Epoch: 80 | Iter: 0 | chi_form: -147.1411-0.0089j | det_g: 0.0017 | einstein_norm: 1.0180 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0142 | ricci_measure: 0.0285 | ricci_scalar: 0.0157 | ricci_tensor_norm: 0.0419 | sigma_measure: 0.0200 | vol_CY: 0.0279 | vol_Omega: 0.7100 | vol_loss: 0.0001\nEpoch: 80: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 526.09it/s, loss: 0.01380]\nEpoch: 81: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 548.99it/s, loss: 0.01327]\nEpoch: 82: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 553.80it/s, loss: 0.01450]\nEpoch: 83: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 548.24it/s, loss: 0.01356]\nEpoch: 84: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 572.65it/s, loss: 0.01379]\n14:27:55 INFO - callback: [148.3s]: [VAL] | Epoch: 85 | Iter: 0 | chi_form: -138.4507+0.0099j | det_g: 0.0017 | einstein_norm: 0.9589 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0136 | ricci_measure: 0.0249 | ricci_scalar: 0.0912 | ricci_tensor_norm: 0.0414 | sigma_measure: 0.0193 | vol_CY: 0.0278 | vol_Omega: 0.7053 | vol_loss: 0.0000\nEpoch: 85: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 541.77it/s, loss: 0.01447]\nEpoch: 86: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 556.41it/s, loss: 0.01459]\nEpoch: 87: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 543.58it/s, loss: 0.01386]\nEpoch: 88: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 556.47it/s, loss: 0.01305]\nEpoch: 89: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 569.38it/s, loss: 0.01432]\n14:28:00 INFO - callback: [153.8s]: [VAL] | Epoch: 90 | Iter: 0 | chi_form: -146.9192-0.0090j | det_g: 0.0017 | einstein_norm: 0.9270 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0141 | ricci_measure: 0.0327 | ricci_scalar: -0.1549 | ricci_tensor_norm: 0.0407 | sigma_measure: 0.0203 | vol_CY: 0.0276 | vol_Omega: 0.7013 | vol_loss: 0.0002\nEpoch: 90: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 549.42it/s, loss: 0.01304]\nEpoch: 91: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 553.62it/s, loss: 0.01467]\nEpoch: 92: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 561.20it/s, loss: 0.01429]\nEpoch: 93: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 569.88it/s, loss: 0.01469]\nEpoch: 94: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 555.88it/s, loss: 0.01326]\n14:28:05 INFO - callback: [159.2s]: [VAL] | Epoch: 95 | Iter: 0 | chi_form: -134.2157+0.0087j | det_g: 0.0017 | einstein_norm: 0.8699 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0125 | ricci_measure: 0.0267 | ricci_scalar: 0.1765 | ricci_tensor_norm: 0.0394 | sigma_measure: 0.0178 | vol_CY: 0.0276 | vol_Omega: 0.6998 | vol_loss: 0.0002\nEpoch: 95: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 564.26it/s, loss: 0.01420]\nEpoch: 96: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 569.56it/s, loss: 0.01387]\nEpoch: 97: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 571.52it/s, loss: 0.01350]\nEpoch: 98: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 573.66it/s, loss: 0.01259]\nEpoch: 99: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 584.08it/s, loss: 0.01261]\n14:28:11 INFO - callback: [164.5s]: [VAL] | Epoch: 100 | Iter: 0 | chi_form: -145.4254+0.0072j | det_g: 0.0017 | einstein_norm: 0.9189 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0136 | ricci_measure: 0.0279 | ricci_scalar: -0.0306 | ricci_tensor_norm: 0.0406 | sigma_measure: 0.0193 | vol_CY: 0.0279 | vol_Omega: 0.7102 | vol_loss: 0.0001\nEpoch: 100: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 541.49it/s, loss: 0.01350]\nEpoch: 101: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 557.09it/s, loss: 0.01390]\nEpoch: 102: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 574.05it/s, loss: 0.01449]\nEpoch: 103: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 565.91it/s, loss: 0.01397]\nEpoch: 104: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 558.86it/s, loss: 0.01302]\n14:28:16 INFO - callback: [169.9s]: [VAL] | Epoch: 105 | Iter: 0 | chi_form: -149.9376-0.0439j | det_g: 0.0018 | einstein_norm: 1.0005 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0140 | ricci_measure: 0.0331 | ricci_scalar: 0.0176 | ricci_tensor_norm: 0.0409 | sigma_measure: 0.0199 | vol_CY: 0.0278 | vol_Omega: 0.7065 | vol_loss: 0.0000\nEpoch: 105: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 576.60it/s, loss: 0.01335]\nEpoch: 106: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 590.34it/s, loss: 0.01331]\nEpoch: 107: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 590.94it/s, loss: 0.01346]\nEpoch: 108: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 588.17it/s, loss: 0.01293]\nEpoch: 109: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 579.40it/s, loss: 0.01316]\n14:28:21 INFO - callback: [175.1s]: [VAL] | Epoch: 110 | Iter: 0 | chi_form: -138.6156+0.0104j | det_g: 0.0017 | einstein_norm: 1.0735 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0131 | ricci_measure: 0.0251 | ricci_scalar: 0.0507 | ricci_tensor_norm: 0.0405 | sigma_measure: 0.0185 | vol_CY: 0.0278 | vol_Omega: 0.7051 | vol_loss: 0.0000\nEpoch: 110: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 528.55it/s, loss: 0.01295]\nEpoch: 111: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 552.33it/s, loss: 0.01392]\nEpoch: 112: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 546.67it/s, loss: 0.01305]\nEpoch: 113: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 547.34it/s, loss: 0.01265]\nEpoch: 114: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 558.66it/s, loss: 0.01343]\n14:28:27 INFO - callback: [180.6s]: [VAL] | Epoch: 115 | Iter: 0 | chi_form: -143.7961+0.0100j | det_g: 0.0017 | einstein_norm: 0.9358 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0139 | ricci_measure: 0.0269 | ricci_scalar: 0.0594 | ricci_tensor_norm: 0.0403 | sigma_measure: 0.0196 | vol_CY: 0.0279 | vol_Omega: 0.7098 | vol_loss: 0.0001\nEpoch: 115: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 542.10it/s, loss: 0.01215]\nEpoch: 116: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.72it/s, loss: 0.01322]\nEpoch: 117: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 566.17it/s, loss: 0.01286]\nEpoch: 118: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.81it/s, loss: 0.01353]\nEpoch: 119: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 549.84it/s, loss: 0.01315]\n14:28:32 INFO - callback: [186.0s]: [VAL] | Epoch: 120 | Iter: 0 | chi_form: -141.6601-0.0063j | det_g: 0.0017 | einstein_norm: 0.8899 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0130 | ricci_measure: 0.0281 | ricci_scalar: 0.0299 | ricci_tensor_norm: 0.0384 | sigma_measure: 0.0183 | vol_CY: 0.0279 | vol_Omega: 0.7103 | vol_loss: 0.0002\nEpoch: 120: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 548.59it/s, loss: 0.01400]\nEpoch: 121: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 542.58it/s, loss: 0.01359]\nEpoch: 122: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 538.37it/s, loss: 0.01296]\nEpoch: 123: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 542.21it/s, loss: 0.01368]\nEpoch: 124: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 551.13it/s, loss: 0.01362]\n14:28:38 INFO - callback: [191.5s]: [VAL] | Epoch: 125 | Iter: 0 | chi_form: -145.2401-0.0202j | det_g: 0.0017 | einstein_norm: 0.8886 | kahler_loss: 0.0000 | monge_ampere_loss: 0.0130 | ricci_measure: 0.0244 | ricci_scalar: -0.0146 | ricci_tensor_norm: 0.0386 | sigma_measure: 0.0186 | vol_CY: 0.0276 | vol_Omega: 0.7028 | vol_loss: 0.0001\nEpoch: 125: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.48it/s, loss: 0.01296]\nEpoch: 126: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 559.61it/s, loss: 0.01254]\nEpoch: 127: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 390/390 [00:00&lt;00:00, 554.74it/s, loss: 0.01302]\n</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nplt.rcParams.update({'font.size': 14})\n# remove if no local tex installation\nplt.rcParams['text.usetex'] = True \nplt.rcParams['text.latex.preamble'] = r'\\usepackage[cm]{sfmath} \\usepackage{amssymb} \\usepackage{mathrsfs} \\usepackage{amsmath}'\nplt.rcParams['font.sans-serif'] = 'cm'\n</code></pre> <pre><code>fig = plt.figure(figsize=(17,7))\ngs=GridSpec(1,2)\nax1=fig.add_subplot(gs[0,0])\nax2=fig.add_subplot(gs[0,1])\n\nS = np.abs(storage['ricci_scalar'])\nn = 32\nax1.plot(np.arange(len(S))[:n], np.abs(S)[:n], c='royalblue')\nax1.set_xlabel(f'Epochs/{eval_interval}')\nax1.set_ylabel(r'$R$')\nax1.grid(True, 'both')\n\nR = storage['ricci_tensor_norm']\nax2.plot(np.arange(len(R))[:n], np.abs(R)[:n], c='royalblue')\nax2.set_xlabel(f'Epochs/{eval_interval}')\nax2.set_ylabel(r'$\\Vert \\textsf{Ric} \\Vert_2$')\nax2.grid(True, 'both')\n</code></pre> <p>Now that we have an approximation to the Ricci-flat metric on \\(X\\), we can use this to do geometry - e.g. measure lengths, areas, volumes, and study the spectrum of various differential operators. See the <code>harmonic_forms</code> example notebook, where we use the learnt metric to find the zero modes of the Laplacian on \\(X\\). </p>"},{"location":"examples/metric_approx/#approximation-of-the-ricci-flat-metric-on-a-manifold","title":"Approximation of the Ricci-flat metric on a manifold","text":"<p>In this example notebook we consider a simple complex manifold \\(X\\), and approximate the metric tensor on \\(X\\) by optimisation of a variational objective derived from a PDE the metric tensor should solve.</p> <p>In more detail, the manifold \\(X\\) is a Calabi-Yau threefold defined as a projective variety in \\(\\mathbb{P}^5\\). This is the (mirror of the) intersection of two cubics in the ambient \\(\\mathbb{P}^5\\).</p> <p>We wish to approximate the unique Ricci-flat metric on \\(X\\) - that is, one whose associated Ricci curvature vanishes. We sample points from the manifold and obtain an approximation to the Ricci-flat metric via optimisation of an objective constructed from the Monge-Ampere equation.</p>"},{"location":"examples/metric_approx/#manifold-definition","title":"Manifold definition","text":"<p>The manifold is explicitly defined as the zero locus of the following polynomials in the complex projective space \\(\\mathbb{P}^5\\), where we let \\(Z_i\\) denote local coordinates in the ambient projective space;</p> \\[\\begin{align*} P_1 &amp;= Z_0^3 + Z_1^3 + Z_2^3 - 3 \\psi Z_3 Z_4 Z_5~, \\\\ P_2 &amp;= Z_3^3 + Z_4^3 + Z_5^3 - 3 \\psi Z_0 Z_1 Z_2~. \\end{align*}\\] <p>The single complex structure moduli direction corresponds to the trilinear polynomial deformations above, parameterised by \\(\\psi \\in \\mathbb{C}\\). We'll choose the point \\(\\psi = 0.5\\) in moduli space, which is away from singularities in the moduli space - see this article for more details.</p>"},{"location":"examples/metric_approx/#point-sampling","title":"Point sampling","text":"<p>We need to sample points from \\(X \\hookrightarrow \\mathbb{P}^n\\) according to a known distribution in order to evaluate integrals via Monte Carlo integration. One way of doing this is to utilise the identification \\(\\mathbb{P}^n \\simeq S^{2n+1} / U(1)\\).</p> <p>First we sample uniformly from the sphere \\(S^{2n+1}\\), obtaining a uniformly distributed sample over \\(\\mathbb{P}^n\\). Next, one constructs a line connecting pairs of points \\(p,q \\in \\mathbb{P}^n\\), and identifies the points of intersection with the zero locus \\(\\{P_i=0\\}_i\\). These points are distributed according to a quantifiable distribution \\(dA\\) on \\(X\\). We correct for the fact that these points are not uniformly distributed according to the canonical measure on \\(X\\) by computing the associated importance weights (Douglas et. al (2008)). </p>"},{"location":"examples/metric_approx/#dataset-metadata","title":"Dataset metadata","text":"<p>Here we save the metadata associated with the generated points to disk.</p>"},{"location":"examples/metric_approx/#ricci-flat-metric-optimisation","title":"Ricci-flat metric optimisation","text":""},{"location":"examples/metric_approx/#model-construction","title":"Model construction","text":"<p>Here we construct a spectral neural network to approximate the Ricci-flat metric. This constructed as an \\(\\partial\\overline{\\partial}\\)-exact correction to the corresponding K\u00e4hler form of some reference metric, one which is easily computable (Larfors et. al. (2022)). $$ \\tilde{\\omega} = \\omega_{\\text{ref}} + \\partial \\overline{\\partial} \\phi~.$$ Thus the task reduces to finding a globally defined function \\(\\phi \\in C^{\\infty}(X)\\) s.t. the metric corresponding to the approximating K\u00e4hler form \\(\\tilde{\\omega}\\) satisfies the Ricci-flat condition, which says that the volume form induced by the metric coincides with the canonical volume form, up to a constant function, $$ \\omega^n \\propto \\Omega \\wedge \\overline{\\Omega} ~.$$ This is a nonlinear PDE on \\(X\\) for the function \\(\\phi\\) - we encode this condition into a variational objective, discretise this via a neural network ansatz, and optimise to obtain a parameterised function describing a approximately Ricci-flat \\(\\tilde{\\omega}\\). Note we are not using the Ricci curvature as the objective itself, as evaluation of third-order derivatives of a neural network is quite expensive - this is possible with our library though. </p> <p>In more detail, our ansatz consists of a projection of the input data \\(p \\in \\mathbb{P}^n\\) into a \\(\\mathbb{C}^*\\)-invariant form, via the mapping \\(\\alpha_{n}\\colon \\mathbb{P}^{n}   \\longrightarrow \\mathbb{C}^{n+1,n+1}\\), whose action on a general point \\(p\\in [Z_0\\colon Z_1\\colon \\dots\\colon Z_{n}]\\in\\mathbb{P}^{n}\\) is defined as:</p> \\[\\alpha_{n}(p) = \\left[\\begin{matrix}         \\displaystyle \\frac{Z_0 \\overline{Z_0}}{|Z|^2} &amp;&amp; \\displaystyle\\frac{Z_0 \\overline{Z_1}}{|Z|^2} &amp;&amp; \\dots &amp;&amp; \\displaystyle\\frac{Z_0 \\overline{Z_{n}}}{|Z|^2} \\\\         \\displaystyle\\frac{Z_1 \\overline{Z_0}}{|Z|^2}  &amp;&amp; \\displaystyle\\frac{Z_1 \\overline{Z_1}}{|Z|^2} &amp;&amp; \\dots &amp;&amp; \\displaystyle\\frac{Z_1 \\overline{Z_{n}}}{|Z|^2} \\\\         \\vdots &amp;&amp; \\vdots &amp;&amp; \\ddots &amp;&amp; \\vdots \\\\         \\displaystyle \\frac{Z_{n} \\overline{Z_0}}{|Z|^2} &amp;&amp; \\displaystyle\\frac{Z_{n} \\overline{Z_1}}{|Z|^2} &amp;&amp; \\dots &amp;&amp; \\displaystyle\\frac{Z_{n} \\overline{Z_{n}}}{|Z|^2}     \\end{matrix}\\right] ~.\\] <p>This is followed by the conversion to real coordinates and the application of a standard feedforward neural network as below - this ensures the overall function learnt is a well-defined function on the ambient projective space.</p> <p></p> <p>Further note that,</p> <ul> <li>The default architecture we use in all our experiments is a four-layer net with 48 units each and results are empirically insensitive to the exact choice of architecture/hyperparameters.</li> <li>The spectral layer adapts to the size of the input - therefore a projective variety with a higher-dimensional description of local coordinates on the ambient space entails an architecture of higher complexity.</li> </ul> <p>Below we define the model and optimiser. </p>"},{"location":"examples/metric_approx/#optimisation-loop","title":"Optimisation loop","text":"<p>This is fairly standard - note Jax is more bare-metal than other libraries, so we write the looping logic ourselves. </p> <p><code>jit</code> compilation introduces a delay the first time the <code>train_step</code> function is called, but executes quickly when called subsequently. We pay an initial up-front cost for compilation of Python functions into a form efficiently executable by an accelerator, which will be repaid during the execution itself.</p>"},{"location":"examples/metric_approx/#sanity-check","title":"Sanity check","text":"<p>As a sanity check, we may verify that the resulting metric is approximately Ricci-flat by investigating the behaviour of the Ricci tensor \\(\\textsf{Ric}\\) and Ricci scalar \\(R\\), defined in terms of the Riemann curvature tensor \\(\\textsf{Riem} \\in \\Omega^2(X; \\textsf{End}(T_X))\\), respectively, over training: \\begin{align} \\textsf{Ric}(X,Y) &amp;= \\textsf{Tr}\\left(Z \\mapsto \\textsf{Riem}(Z,X)Y\\right), \\quad X, Y \\in \\Gamma(T_X)~,\\ R &amp;= \\textsf{Tr}(\\textsf{Ric})~. \\end{align}</p>"},{"location":"examples/workflow/","title":"Example workflow","text":"<p>If you have a particular Calabi-Yau in mind you want to investigate, this example walks you through how to do this using the main scripts in the library. The arguments for each script should be amply documented, accessible using the <code>-h</code> flag. To begin, navigate to the root directory of the repository.</p>"},{"location":"examples/workflow/#manifold-definition-point-sampling","title":"Manifold definition / point sampling","text":"<p>Here we take as example the mirror to the manifold \\(\\mathbb{P}^5[3,3]\\). This is defined as the intersection of the zero loci of the following polynomials in \\(\\mathbb{P}^5\\),</p> \\[\\begin{align*}     P_1 &amp;= Z_0^3 + Z_1^3 + Z_2^3 - 3 \\psi Z_3 Z_4 Z_5~, \\\\     P_2 &amp;= Z_3^3 + Z_4^3 + Z_5^3 - 3 \\psi Z_0 Z_1 Z_2~. \\end{align*}\\] <p>This manifold has a single complex structure modulus - see this article for more details. We choose the point \\(\\psi = 1/2\\) in complex structure moduli space. The following script samples 320000 points from the above zero locus, together with 64000 validation points, saving it to the directory <code>data/X33</code>. </p> <p>!!! info     Point sampling occurs with respect to a given choice of the complex structure moduli, currently one may consider the complex structure of the approximate metric fixed by this stage. </p> <pre><code>python3 -m cymyc.utils.pointgen_cicy -o data/X33 -n_p 320000 -val 0.2 -psi 0.5\n</code></pre> <p>To register your favorite manifold with this library, you will need to know the zero locus it traces out. add the definition to <code>examples/poly_spec.py</code>, following the conventions within, and reference it as appropriate downstream.</p>"},{"location":"examples/workflow/#metric-optimisation","title":"Metric optimisation","text":"<p>To obtain an approximation to the Ricci-flat metric on \\(\\mathbb{P}^5[3,3]\\), run the following script:</p> <p><pre><code>python3 -m cymyc.approx.train -name X33_metric -ds data/X33\n</code></pre> This will output the parameters of the neural network approximating the Ricci-flat metric to the directory <code>experiments/X33_metric/</code>. One may now compute geometric quantities using this approximate metric using the routines in <code>src/curvature</code>, or compute exponential maps / geodesics etc. using the <code>diffrax</code> library. </p>"},{"location":"examples/workflow/#harmonic-form-approximation","title":"Harmonic form approximation","text":"<p>To approximate harmonic differential forms and thereby Yukawa couplings on \\(\\mathbb{P}^5[3,3]\\), run the following script, supplying the path to the model checkpoint of the approximate metric saved at the end of the optimisation process, found under <code>experiments/X33_metric</code>. </p> <pre><code>python3 -m cymyc.approx.eta_train -name X33_harmonic -ds data/X33 -ckpt /path/to/metric/checkpoint\n</code></pre> <p>More information about the library may be found in the API docs - feel free to get in touch with any questions.</p>"},{"location":"examples/workflow/#complex-structure-moduli","title":"Complex structure moduli","text":"<p>One may obtain the Weil--Petersson metric over complex structure moduli space for Calabi-Yau manifolds with any number of complex structure moduli via the routines in <code>src/moduli/moduli_scan</code>. This computation is based on deformation theory and does not involve period integrals or any approximation. It is exact up to Monte Carlo integration error, and serves as a sanity check for the approximations to the moduli metric obtained using harmonic forms.</p> <p>See <code>examples/tian_yau</code> for scripts which evaluate the moduli space metric over moduli space with dimension \\(h^{2,1} = 9\\).</p>"}]}